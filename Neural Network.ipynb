{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "def create_model():\n",
    "  return tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28), name='layers_flatten'),\n",
    "    tf.keras.layers.Dense(512, activation='relu', name='layers_dense'),\n",
    "    tf.keras.layers.Dropout(0.2, name='layers_dropout'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax', name='layers_dense_2')\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.curdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir(): \n",
    "    import time \n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\") \n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=run_logdir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\my_logs\\\\run_2023_07_24-11_02_12'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1875/1875 [==============================] - 9s 4ms/step - loss: 0.2189 - accuracy: 0.9347 - val_loss: 0.1115 - val_accuracy: 0.9657\n",
      "Epoch 2/30\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0966 - accuracy: 0.9704 - val_loss: 0.0781 - val_accuracy: 0.9754\n",
      "Epoch 3/30\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0674 - accuracy: 0.9791 - val_loss: 0.0834 - val_accuracy: 0.9742\n",
      "Epoch 4/30\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0530 - accuracy: 0.9830 - val_loss: 0.0746 - val_accuracy: 0.9761\n",
      "Epoch 5/30\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0419 - accuracy: 0.9863 - val_loss: 0.0774 - val_accuracy: 0.9769\n",
      "Epoch 6/30\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0377 - accuracy: 0.9876 - val_loss: 0.0665 - val_accuracy: 0.9802\n",
      "Epoch 7/30\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0325 - accuracy: 0.9888 - val_loss: 0.0656 - val_accuracy: 0.9820\n",
      "Epoch 8/30\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0259 - accuracy: 0.9913 - val_loss: 0.0637 - val_accuracy: 0.9840\n",
      "Epoch 9/30\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0227 - accuracy: 0.9920 - val_loss: 0.0753 - val_accuracy: 0.9808\n",
      "Epoch 10/30\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0216 - accuracy: 0.9929 - val_loss: 0.0745 - val_accuracy: 0.9812\n",
      "Epoch 11/30\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0222 - accuracy: 0.9926 - val_loss: 0.0774 - val_accuracy: 0.9818\n",
      "Epoch 12/30\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0174 - accuracy: 0.9939 - val_loss: 0.0821 - val_accuracy: 0.9806\n",
      "Epoch 13/30\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0184 - accuracy: 0.9942 - val_loss: 0.0756 - val_accuracy: 0.9820\n",
      "Epoch 14/30\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0178 - accuracy: 0.9940 - val_loss: 0.0877 - val_accuracy: 0.9814\n",
      "Epoch 15/30\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0159 - accuracy: 0.9944 - val_loss: 0.0876 - val_accuracy: 0.9814\n",
      "Epoch 16/30\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0148 - accuracy: 0.9950 - val_loss: 0.0912 - val_accuracy: 0.9818\n",
      "Epoch 17/30\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0135 - accuracy: 0.9952 - val_loss: 0.0885 - val_accuracy: 0.9826\n",
      "Epoch 18/30\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0148 - accuracy: 0.9953 - val_loss: 0.0970 - val_accuracy: 0.9827\n",
      "Epoch 19/30\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0142 - accuracy: 0.9952 - val_loss: 0.1006 - val_accuracy: 0.9823\n",
      "Epoch 20/30\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.0929 - val_accuracy: 0.9823\n",
      "Epoch 21/30\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0106 - accuracy: 0.9966 - val_loss: 0.0992 - val_accuracy: 0.9819\n",
      "Epoch 22/30\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0123 - accuracy: 0.9960 - val_loss: 0.1016 - val_accuracy: 0.9815\n",
      "Epoch 23/30\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0128 - accuracy: 0.9959 - val_loss: 0.0987 - val_accuracy: 0.9816\n",
      "Epoch 24/30\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0134 - accuracy: 0.9959 - val_loss: 0.0928 - val_accuracy: 0.9838\n",
      "Epoch 25/30\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0101 - accuracy: 0.9966 - val_loss: 0.1138 - val_accuracy: 0.9820\n",
      "Epoch 26/30\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0125 - accuracy: 0.9960 - val_loss: 0.0971 - val_accuracy: 0.9837\n",
      "Epoch 27/30\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0100 - accuracy: 0.9968 - val_loss: 0.1119 - val_accuracy: 0.9819\n",
      "Epoch 28/30\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0111 - accuracy: 0.9965 - val_loss: 0.1092 - val_accuracy: 0.9827\n",
      "Epoch 29/30\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0114 - accuracy: 0.9965 - val_loss: 0.1088 - val_accuracy: 0.9837\n",
      "Epoch 30/30\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0089 - accuracy: 0.9973 - val_loss: 0.1074 - val_accuracy: 0.9839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2071c58e590>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x_train, \n",
    "          y=y_train, \n",
    "          epochs=30, \n",
    "          validation_data=(x_test, y_test), \n",
    "          callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=.\\\\my_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split( housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split( X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler() \n",
    "X_train_scaled = scaler.fit_transform(X_train) \n",
    "X_valid_scaled = scaler.transform(X_valid) \n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    options = {\"input_shape\": input_shape}\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\", **options))\n",
    "        options = {}\n",
    "    model.add(keras.layers.Dense(1, **options))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikeras[tensorflow]\n",
      "  Obtaining dependency information for scikeras[tensorflow] from https://files.pythonhosted.org/packages/41/6f/53606bacb79e64f30d23410e15f3034447e97a33850d5d4366abdcf7ed84/scikeras-0.11.0-py3-none-any.whl.metadata\n",
      "  Downloading scikeras-0.11.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: packaging>=0.21 in c:\\users\\tmoia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikeras[tensorflow]) (23.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\tmoia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikeras[tensorflow]) (1.3.0)\n",
      "Requirement already satisfied: tensorflow>=2.11.0 in c:\\users\\tmoia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikeras[tensorflow]) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem<0.32,>=0.23.1 in c:\\users\\tmoia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikeras[tensorflow]) (0.31.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\tmoia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn>=1.0.0->scikeras[tensorflow]) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\tmoia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn>=1.0.0->scikeras[tensorflow]) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\tmoia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn>=1.0.0->scikeras[tensorflow]) (1.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\tmoia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn>=1.0.0->scikeras[tensorflow]) (3.2.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.13.0 in c:\\users\\tmoia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow>=2.11.0->scikeras[tensorflow]) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\tmoia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow>=2.11.0->scikeras[tensorflow]) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\tmoia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow>=2.11.0->scikeras[tensorflow]) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\tmoia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow>=2.11.0->scikeras[tensorflow]) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\tmoia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow>=2.11.0->scikeras[tensorflow]) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\tmoia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow>=2.11.0->scikeras[tensorflow]) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\tmoia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow>=2.11.0->scikeras[tensorflow]) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\tmoia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow>=2.11.0->scikeras[tensorflow]) (16.0.6)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\tmoia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow>=2.11.0->scikeras[tensorflow]) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\tmoia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow>=2.11.0->scikeras[tensorflow]) (4.23.4)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\windowsapps\\pythonsoftwarefoundation.python.3.11_3.11.1264.0_x64__qbz5n2kfra8p0\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow>=2.11.0->scikeras[tensorflow]) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\tmoia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow>=2.11.0->scikeras[tensorflow]) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\tmoia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow>=2.11.0->scikeras[tensorflow]) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\tmoia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow>=2.11.0->scikeras[tensorflow]) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\tmoia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow>=2.11.0->scikeras[tensorflow]) (1.15.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\tmoia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow>=2.11.0->scikeras[tensorflow]) (1.56.2)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\users\\tmoia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow>=2.11.0->scikeras[tensorflow]) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\tmoia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow>=2.11.0->scikeras[tensorflow]) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in c:\\users\\tmoia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow>=2.11.0->scikeras[tensorflow]) (2.13.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\tmoia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow>=2.11.0->scikeras[tensorflow]) (0.41.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\tmoia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow>=2.11.0->scikeras[tensorflow]) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\tmoia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow>=2.11.0->scikeras[tensorflow]) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\tmoia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow>=2.11.0->scikeras[tensorflow]) (3.4.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\tmoia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow>=2.11.0->scikeras[tensorflow]) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\tmoia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow>=2.11.0->scikeras[tensorflow]) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\tmoia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow>=2.11.0->scikeras[tensorflow]) (2.3.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\tmoia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow>=2.11.0->scikeras[tensorflow]) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\tmoia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow>=2.11.0->scikeras[tensorflow]) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\tmoia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow>=2.11.0->scikeras[tensorflow]) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\tmoia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow>=2.11.0->scikeras[tensorflow]) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\tmoia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow>=2.11.0->scikeras[tensorflow]) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tmoia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow>=2.11.0->scikeras[tensorflow]) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tmoia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow>=2.11.0->scikeras[tensorflow]) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tmoia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow>=2.11.0->scikeras[tensorflow]) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\tmoia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow>=2.11.0->scikeras[tensorflow]) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\tmoia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow>=2.11.0->scikeras[tensorflow]) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\tmoia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow>=2.11.0->scikeras[tensorflow]) (3.2.2)\n",
      "Downloading scikeras-0.11.0-py3-none-any.whl (27 kB)\n",
      "Installing collected packages: scikeras\n",
      "Successfully installed scikeras-0.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikeras[tensorflow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikeras\n",
    "from scikeras.wrappers import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg =  KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3802 - val_loss: 0.7364\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6714 - val_loss: 0.6231\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5859 - val_loss: 0.5680\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5405 - val_loss: 0.8665\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5140 - val_loss: 0.5158\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5055 - val_loss: 0.6492\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4797 - val_loss: 0.4875\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4784 - val_loss: 0.5876\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4570 - val_loss: 0.4860\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4581 - val_loss: 0.5080\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4449 - val_loss: 0.4785\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4354 - val_loss: 0.4789\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4286 - val_loss: 0.4597\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4249 - val_loss: 0.4855\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4188 - val_loss: 0.4594\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4131 - val_loss: 0.5101\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4112 - val_loss: 0.4227\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4109 - val_loss: 0.4904\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4042 - val_loss: 0.4286\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4006 - val_loss: 0.4319\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3975 - val_loss: 0.4276\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3957 - val_loss: 0.4212\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3928 - val_loss: 0.4078\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3911 - val_loss: 0.4170\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3893 - val_loss: 0.4165\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3883 - val_loss: 0.4211\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3858 - val_loss: 0.4105\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3841 - val_loss: 0.4082\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3821 - val_loss: 0.4084\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3813 - val_loss: 0.4388\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3812 - val_loss: 0.3939\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3780 - val_loss: 0.5215\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3777 - val_loss: 0.3900\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3778 - val_loss: 0.4470\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3744 - val_loss: 0.3884\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3764 - val_loss: 0.4290\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3727 - val_loss: 0.3904\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3702 - val_loss: 0.4568\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3728 - val_loss: 0.3840\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3684 - val_loss: 0.3974\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3672 - val_loss: 0.4012\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3664 - val_loss: 0.4005\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3651 - val_loss: 0.3926\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3645 - val_loss: 0.3905\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3633 - val_loss: 0.4176\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3628 - val_loss: 0.4144\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3636 - val_loss: 0.3862\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3612 - val_loss: 0.3841\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3603 - val_loss: 0.3959\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3600 - val_loss: 0.3765\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3605 - val_loss: 0.4179\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3598 - val_loss: 0.3756\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3590 - val_loss: 0.3945\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3577 - val_loss: 0.3800\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3561 - val_loss: 0.4693\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3563 - val_loss: 0.3763\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3552 - val_loss: 0.4698\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3552 - val_loss: 0.3908\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3543 - val_loss: 0.3778\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3553 - val_loss: 0.3935\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3534 - val_loss: 0.3733\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3523 - val_loss: 0.3725\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3525 - val_loss: 0.4561\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3568 - val_loss: 0.3732\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3511 - val_loss: 0.4034\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3520 - val_loss: 0.3842\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3503 - val_loss: 0.3730\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3501 - val_loss: 0.4074\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3528 - val_loss: 0.3713\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3488 - val_loss: 0.3812\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3509 - val_loss: 0.3657\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3482 - val_loss: 0.3770\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3485 - val_loss: 0.3626\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3475 - val_loss: 0.4437\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3515 - val_loss: 0.3688\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3469 - val_loss: 0.3790\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3459 - val_loss: 0.3726\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3451 - val_loss: 0.3754\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3459 - val_loss: 0.3686\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3451 - val_loss: 0.3716\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3445 - val_loss: 0.3670\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3448 - val_loss: 0.3702\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3444 - val_loss: 0.5239\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3535 - val_loss: 0.3796\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3429 - val_loss: 0.4115\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3446 - val_loss: 0.3960\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3450 - val_loss: 0.3582\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3417 - val_loss: 0.3641\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3419 - val_loss: 0.3729\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3406 - val_loss: 0.5216\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3409 - val_loss: 0.4644\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3511 - val_loss: 0.3732\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3394 - val_loss: 0.4372\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3456 - val_loss: 0.3641\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3386 - val_loss: 0.3652\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3381 - val_loss: 0.3688\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3378 - val_loss: 0.3867\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3416 - val_loss: 0.3603\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3365 - val_loss: 0.3590\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3367 - val_loss: 0.3530\n",
      "162/162 [==============================] - 0s 759us/step\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    }
   ],
   "source": [
    "keras_reg.fit(X_train_scaled, y_train, epochs=100,\n",
    "              validation_data=(X_valid_scaled, y_valid),\n",
    "              callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "mse_test = keras_reg.score(X_test_scaled, y_test)\n",
    "y_pred = keras_reg.predict(X_test[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden, n_neurons, meta):\n",
    "    model = keras.models.Sequential()\n",
    "    # note that I added the meta parameter, you can access all of the SciKeras attributes\n",
    "    # https://scikeras.readthedocs.io/en/latest/generated/scikeras.wrappers.KerasRegressor.html\n",
    "    n_features_in_ = meta[\"n_features_in_\"]\n",
    "    model.add(keras.layers.InputLayer(input_shape=(n_features_in_, )))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    return model  # note that I return an un-compiled model here, SciKeras will compile it for you!\n",
    "\n",
    "\n",
    "keras_reg = scikeras.wrappers.KerasRegressor(\n",
    "    build_model,\n",
    "    n_neurons=30,\n",
    "    n_hidden=1,\n",
    "    optimizer__lr=3e-3,  # just specify parameters here, you won't have to edit build_model to add/remove things you're tuning\n",
    "    optimizer=keras.optimizers.SGD,  # note that I am giving SciKeras a class, not an instance\n",
    "   loss=\"mse\",\n",
    ")\n",
    "    \n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\" : [0, 1, 2, 3],\n",
    "    \"n_neurons\" : np.arange(1, 100, 10),\n",
    "    \"optimizer__lr\" : np.arange(3e-4, 3e-2, 0.3*(1e-2 - 1e-4))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x207467f5510>,\n",
       " <matplotlib.lines.Line2D at 0x20746c36310>,\n",
       " <matplotlib.lines.Line2D at 0x20746c5b790>,\n",
       " <matplotlib.lines.Line2D at 0x20746c5bb50>,\n",
       " <matplotlib.lines.Line2D at 0x20746c5bf90>,\n",
       " <matplotlib.lines.Line2D at 0x20746c74150>,\n",
       " <matplotlib.lines.Line2D at 0x20746c74850>,\n",
       " <matplotlib.lines.Line2D at 0x20746c74b50>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjEAAAGdCAYAAADjWSL8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAzuklEQVR4nO3dfXRU9Z3H8c/MhIRAmImhJEM6ZEhNXEjF1vI4QrtdzBptsFqwrS5i3GZlS4MVaK2yVeza1njo2drag0JsCpyjLC3niC3ZootI8YEIIS0tYsWkgskYJrFiMgRNApm7f3Ay68AEc8NkJpd5v865Z5vv/d2Z7/0d2vnsfbQZhmEIAADAYuyJbgAAAGAwCDEAAMCSCDEAAMCSCDEAAMCSCDEAAMCSCDEAAMCSCDEAAMCSCDEAAMCSUhLdwGCEQiG1tLRozJgxstlsiW4HAAAMgGEYOnHihHJzc2W3X/hxFEuGmJaWFk2YMCHRbQAAgEFobm6Wx+O54M+xZIgZM2aMpDOT4HQ6E9wNAAAYiGAwqAkTJoR/xy+UqRAzceJEvf322+fUv/Wtb2nNmjXq6urSd77zHW3evFnd3d0qKSnRY489ppycnPDYpqYmLVmyRLt27VJGRobKyspUWVmplJSBt9J3CsnpdBJiAACwmFhdCmLqhFRdXZ2OHTsWXnbs2CFJ+upXvypJWr58ubZt26YtW7Zo9+7damlp0fz588Pb9/b2qrS0VD09PdqzZ482btyoDRs2aNWqVTHZGQAAkDxsF/IW62XLlqmmpkYNDQ0KBoMaN26cNm3apJtuukmS9MYbb2jy5Mmqra3VrFmztH37ds2bN08tLS3hozNr167VPffco3fffVepqakD+t5gMCiXy6WOjg6OxAAAYBGx/v0e9KXBPT09evLJJ/WNb3xDNptN9fX1OnXqlIqLi8NjJk2apLy8PNXW1kqSamtrNWXKlIjTSyUlJQoGgzp06FC/39Xd3a1gMBixAACA5DboEPPMM8+ovb1dt99+uyQpEAgoNTVVmZmZEeNycnIUCATCYz4aYPrW963rT2VlpVwuV3jhziQAADDoEFNdXa3rrrtOubm5sewnqpUrV6qjoyO8NDc3D/l3AgCA4W1Qt1i//fbbev755/X000+Ha263Wz09PWpvb484GtPa2iq32x0es2/fvojPam1tDa/rT1pamtLS0gbTKgAAuEgN6kjM+vXrlZ2drdLS0nBt6tSpGjFihHbu3BmuHT58WE1NTfL5fJIkn8+ngwcPqq2tLTxmx44dcjqdKioqGuw+AACAJGT6SEwoFNL69etVVlYW8WwXl8ul8vJyrVixQllZWXI6nbrzzjvl8/k0a9YsSdI111yjoqIiLVq0SKtXr1YgENB9992niooKjrQAAABTTIeY559/Xk1NTfrGN75xzrpHHnlEdrtdCxYsiHjYXR+Hw6GamhotWbJEPp9Po0ePVllZmR588MEL2wsAAJB0Lug5MYnCc2IAALCeYfOcmGTn9/u1a9cu+f3+RLcCAEBSIsQMQnV1tbxer+bOnSuv16vq6upEtwQAQNLhdJJJfr9feXl5+ui02e12vf322zF5rTgAABcrTicl2J49e3R27guFQuFXKwAAgPggxAAAAEsixJiUn58ftT5x4sT4NgIAQJIjxJjU2dkZtX7y5Mk4dwIAQHIjxJhUWFgouz1y2hwOhwoKChLUEQAAyYkQY5LH41FVVZUcDoekMwFm3bp13JkEAECccYv1IPn9fjU2NqqgoIAAAwDAAMT699v0u5NwhsfjIbwAAJBAnE4CAACWRIgBAACWRIgBAACWRIgBAACWRIgBAACWRIgBAACWRIgBAACWRIgBAACWRIgBAACWRIgBAACWRIgBAACWRIgBAACWRIgBAACWRIgBAACWRIgBAACWRIgBAACWRIgBAACWRIgBAACWRIgBAACWRIgBAACWRIgBAACWRIgBAACWRIgBAACWRIgBAACWRIgBAACWRIgBAACWRIgBAACWRIgBAACWZDrEvPPOO7r11ls1duxYpaena8qUKdq/f394vWEYWrVqlcaPH6/09HQVFxeroaEh4jOOHz+uhQsXyul0KjMzU+Xl5ers7LzwvQEAAEnDVIh5//33NXv2bI0YMULbt2/X66+/rv/6r//SJZdcEh6zevVqPfroo1q7dq327t2r0aNHq6SkRF1dXeExCxcu1KFDh7Rjxw7V1NToxRdf1OLFi2O3VwAA4KJnMwzDGOjge++9V6+88opeeumlqOsNw1Bubq6+853v6Lvf/a4kqaOjQzk5OdqwYYNuvvlm/fWvf1VRUZHq6uo0bdo0SdKzzz6rL33pS/L7/crNzf3YPoLBoFwulzo6OuR0OgfaPgAASKBY/36bOhLzu9/9TtOmTdNXv/pVZWdn68orr9QTTzwRXn/kyBEFAgEVFxeHay6XSzNnzlRtba0kqba2VpmZmeEAI0nFxcWy2+3au3dv1O/t7u5WMBiMWAAAQHIzFWLeeustPf744yosLNRzzz2nJUuW6Nvf/rY2btwoSQoEApKknJyciO1ycnLC6wKBgLKzsyPWp6SkKCsrKzzmbJWVlXK5XOFlwoQJZtoeEunp6bLZbEpPT090KwAAJCVTISYUCulzn/ucHnroIV155ZVavHix7rjjDq1du3ao+pMkrVy5Uh0dHeGlubl5SL/v49hstvA1Pl1dXbLZbAntBwCAZGQqxIwfP15FRUURtcmTJ6upqUmS5Ha7JUmtra0RY1pbW8Pr3G632traItafPn1ax48fD485W1pampxOZ8SSKP0deeGIDAAA8WUqxMyePVuHDx+OqL355pvyer2SpPz8fLndbu3cuTO8PhgMau/evfL5fJIkn8+n9vZ21dfXh8e88MILCoVCmjlz5qB3JF4+epfVQOoAAGBopJgZvHz5cl111VV66KGH9LWvfU379u1TVVWVqqqqJJ05zbJs2TL96Ec/UmFhofLz83X//fcrNzdXN954o6QzR26uvfba8GmoU6dOaenSpbr55psHdGdSoo0cOTJqYBk5cmQCugEAIHmZusVakmpqarRy5Uo1NDQoPz9fK1as0B133BFebxiGHnjgAVVVVam9vV1z5szRY489pssuuyw85vjx41q6dKm2bdsmu92uBQsW6NFHH1VGRsaAekj0LdbRroExOY0AACSdWP9+mw4xw0EiQ4zf75fX61UoFArXHA6Hjh49Ko/HE9deAACwkoQ+JwZSQ0NDRICRpN7eXjU2NiaoIwAAkhMhxqTCwkLZ7ZHT5nA4VFBQkKCOAABIToQYkzwej6qqquRwOCSdCTDr1q3jVBIAAHFm6u4knFFeXq4rrrhCL7/8subMmaPp06cnuiUAAJIOIWYQqqurtXjxYoVCIdntdlVVVam8vDzRbQEAkFS4O8kk7k4CAGBwuDspwbg7CQCA4YEQYxJ3JwEAMDwQYkzi7iQAAIYHrokZJL/fr8bGRhUUFBBgAAAYgFj/fnN30iB5PB7CCwAACcTpJAAAYEmEGAAAYEmEGAAAYEmEGAAAYEmEGAAAYEmEGAAAYEmEGAAAYEmEGAAAYEmEGAAAYEmEGAAAYEmEGAAAYEmEGAAAYEmEGAAAYEmEGAAAYEmEmEHy+/3atWuX/H5/olsBACApEWIGobq6Wl6vV3PnzpXX61V1dXWiWwIAIOnYDMMwEt2EWcFgUC6XSx0dHXI6nXH9br/fL6/Xq1AoFK45HA4dPXpUHo8nrr0AAGAlsf795kiMSQ0NDREBRpJ6e3vV2NiYoI4AAEhOhBiTCgsLZbdHTpvD4VBBQUGCOgIAIDkRYkzyeDyqqqqSw+GQdCbArFu3jlNJAADEGdfEDJLf71djY6MKCgoIMAAADECsf79TYtBTUvJ4PIQXAAASiNNJg8RzYgAASCxCzCDwnBgAABKPa2JM4jkxAAAMDs+JSTCeEwMAwPBAiDGJ58QAADA8mAoxP/jBD2Sz2SKWSZMmhdd3dXWpoqJCY8eOVUZGhhYsWKDW1taIz2hqalJpaalGjRql7Oxs3X333Tp9+nRs9iYOeE4MAADDg+lbrD/96U/r+eef//8PSPn/j1i+fLn+53/+R1u2bJHL5dLSpUs1f/58vfLKK5LOnHYpLS2V2+3Wnj17dOzYMd12220aMWKEHnrooRjsTnyUl5erpKSE58QAAJBApi7s/cEPfqBnnnlGBw4cOGddR0eHxo0bp02bNummm26SJL3xxhuaPHmyamtrNWvWLG3fvl3z5s1TS0uLcnJyJElr167VPffco3fffVepqakD6mM4POwOAACYk/ALexsaGpSbm6tPfepTWrhwoZqamiRJ9fX1OnXqlIqLi8NjJ02apLy8PNXW1kqSamtrNWXKlHCAkaSSkhIFg0EdOnSo3+/s7u5WMBiMWAAAQHIzFWJmzpypDRs26Nlnn9Xjjz+uI0eO6POf/7xOnDihQCCg1NRUZWZmRmyTk5OjQCAgSQoEAhEBpm9937r+VFZWyuVyhZcJEyaYaRsAAFyETF0Tc91114X/8xVXXKGZM2fK6/XqN7/5jdLT02PeXJ+VK1dqxYoV4b+DwSBBBgCAJHdBt1hnZmbqsssuU2Njo9xut3p6etTe3h4xprW1VW63W5LkdrvPuVup7+++MdGkpaXJ6XRGLAAAILldUIjp7OzU3/72N40fP15Tp07ViBEjtHPnzvD6w4cPq6mpST6fT5Lk8/l08OBBtbW1hcfs2LFDTqdTRUVFF9IKAABIMqZOJ333u9/V9ddfL6/Xq5aWFj3wwANyOBy65ZZb5HK5VF5erhUrVigrK0tOp1N33nmnfD6fZs2aJUm65pprVFRUpEWLFmn16tUKBAK67777VFFRobS0tCHZQQAAcHEyFWL8fr9uueUWvffeexo3bpzmzJmjV199VePGjZMkPfLII7Lb7VqwYIG6u7tVUlKixx57LLy9w+FQTU2NlixZIp/Pp9GjR6usrEwPPvhgbPcKAABc9HgB5CD5/X41NDSosLCQh90BADAACX9ODKTq6mp5vV7NnTtXXq9X1dXViW4JAICkw5EYk/x+v7xeb8SbrB0Oh44ePcoRGQAAzoMjMQnW0NAQEWCkM++EamxsTFBHAAAkJ0KMSYWFhbLbI6fN4XCooKAgQR0BAJCcCDEmeTweVVVVyeFwSDoTYNatW8epJAAA4oxrYgbJ7/ersbFRBQUFBBgAAAYg1r/fpp4Tg//n8XgILwAAJBCnkwAAgCURYgAAgCURYgAAgCURYgAAgCURYgAAgCURYgAAgCURYgAAgCURYgAAgCURYgAAgCURYgAAgCURYgAAgCURYgAAgCURYgAAgCURYgAAgCURYgAAgCURYgAAgCURYgAAgCURYgAAgCURYgAAgCURYgAAgCURYgAAgCURYgAAgCURYgAAgCURYgAAgCURYgAAgCURYgAAgCURYgAAgCURYgAAgCURYgAAgCURYgbJ7/dr165d8vv9iW4FAICkRIgZhOrqanm9Xs2dO1der1fV1dWJbgkAgKRjMwzDSHQTZgWDQblcLnV0dMjpdMb1u/1+v7xer0KhULjmcDh09OhReTyeuPYCAICVxPr3+4KOxDz88MOy2WxatmxZuNbV1aWKigqNHTtWGRkZWrBggVpbWyO2a2pqUmlpqUaNGqXs7GzdfffdOn369IW0EjcNDQ0RAUaSent71djYmKCOAABIToMOMXV1dVq3bp2uuOKKiPry5cu1bds2bdmyRbt371ZLS4vmz58fXt/b26vS0lL19PRoz5492rhxozZs2KBVq1YNfi/iqLCwUHZ75LQ5HA4VFBQkqCMAAJLToEJMZ2enFi5cqCeeeEKXXHJJuN7R0aHq6mr99Kc/1dy5czV16lStX79ee/bs0auvvipJ+t///V+9/vrrevLJJ/XZz35W1113nX74wx9qzZo16unpic1eDSGPx6Oqqio5HA5JZwLMunXrOJUEAECcDSrEVFRUqLS0VMXFxRH1+vp6nTp1KqI+adIk5eXlqba2VpJUW1urKVOmKCcnJzympKREwWBQhw4divp93d3dCgaDEUsilZeX6+jRo9q1a5eOHj2q8vLyhPYDAEAySjG7webNm/XHP/5RdXV156wLBAJKTU1VZmZmRD0nJ0eBQCA85qMBpm9937poKisr9Z//+Z9mWx1SHo+Hoy8AACSQqSMxzc3Nuuuuu/TUU09p5MiRQ9XTOVauXKmOjo7w0tzcHLfvBgAAw5OpEFNfX6+2tjZ97nOfU0pKilJSUrR79249+uijSklJUU5Ojnp6etTe3h6xXWtrq9xutyTJ7Xafc7dS3999Y86WlpYmp9MZsQAAgORmKsRcffXVOnjwoA4cOBBepk2bpoULF4b/84gRI7Rz587wNocPH1ZTU5N8Pp8kyefz6eDBg2prawuP2bFjh5xOp4qKimK0W0OPJ/YCAJBYpq6JGTNmjC6//PKI2ujRozV27Nhwvby8XCtWrFBWVpacTqfuvPNO+Xw+zZo1S5J0zTXXqKioSIsWLdLq1asVCAR03333qaKiQmlpaTHaraFVXV2txYsXKxQKyW63q6qqiot7AQCIs5i/duCRRx7RvHnztGDBAn3hC1+Q2+3W008/HV7vcDhUU1Mjh8Mhn8+nW2+9VbfddpsefPDBWLcyJPx+fzjASFIoFNK///u/c0QGAIA447UDJu3atUtz586NWv/iF78Y114AALCSYfXagWTEE3sBABgeCDEm8cReAACGB04nDZLf71djY6MKCgoIMAAADACnk4aJ559/Xo888oief/75RLcCAEBS4kjMIBQUFOhvf/tb+O9LL71UjY2Nce8DAAAr4UhMgm3YsCEiwEjS3/72N23YsCExDQEAkKQIMSZt3bo1av23v/1tnDsBACC5EWJM+spXvhK1fsMNN8S5EwAAkhvXxAwC18QAAGAe18QMA42NjVq/fr1uvPFGrV+/ngADAEACcCQGAADEBUdiAAAARIgBAAAWRYgZJL/fr127dsnv9ye6FQAAkhIhZhCqq6vl9Xo1d+5ceb1eVVdXJ7olAACSDhf2muT3++X1ehUKhcI1h8Oho0eP8iJIAADOgwt7E6yhoSEiwEhSb28vt1kDABBnhBiTCgsLZbdHTpvD4VBBQUGCOgIAIDkRYkzyeDyqqqqSw+GQdCbArFu3jlNJAADEGdfEDJLf71djY6MKCgoIMAAADECsf79TYtBTUvJ4PIQXAAASiNNJAADAkggxg1RXV6ef/vSnqqurS3QrAAAkJU4nDcLtt9+ujRs3hv8uKyvThg0bEtcQAABJiCMxJtXV1UUEGEnauHEjR2QAAIgzQoxJL730UtT6K6+8EudOAABIboQYkz7/+c9Hrc+ePTvOnQAAkNwIMSaNHz/eVB0AAAwNQoxJDQ0NUeu8OwkAgPgixJjEu5MAABgeCDEmeTweLVq0KKJ266238vReAADijHcnmeT3+5WXl6ePTpvNZlNTUxNBBgCA84j17zdHYkzas2ePzs59hmGotrY2QR0BAJCcCDEAAMCSCDEmXXXVVbLZbBE1u90un8+XoI4AAEhOhBiTPB6PnnjiCTkcDkln7kyqqqriehgAAOKMC3sHye/3q7GxUQUFBQQYAAAGINa/37zFepA8Hg/hBQCABDJ1Ounxxx/XFVdcIafTKafTKZ/Pp+3bt4fXd3V1qaKiQmPHjlVGRoYWLFig1tbWiM9oampSaWmpRo0apezsbN199906ffp0bPYmjvx+v3bt2iW/35/oVgAASEqmQozH49HDDz+s+vp67d+/X3PnztUNN9ygQ4cOSZKWL1+ubdu2acuWLdq9e7daWlo0f/788Pa9vb0qLS1VT0+P9uzZo40bN2rDhg1atWpVbPdqiFVXV8vr9Wru3Lnyer2qrq5OdEsAACSdC74mJisrSz/5yU900003ady4cdq0aZNuuukmSdIbb7yhyZMnq7a2VrNmzdL27ds1b948tbS0KCcnR5K0du1a3XPPPXr33XeVmpo6oO9M9MPuvF6vQqFQuOZwOHT06FFOLwEAcB7D5mF3vb292rx5s06ePCmfz6f6+nqdOnVKxcXF4TGTJk1SXl5e+EFwtbW1mjJlSjjASFJJSYmCwWD4aE403d3dCgaDEUuiNDQ0RAQY6cxc8AJIAADiy3SIOXjwoDIyMpSWlqZvfvOb2rp1q4qKihQIBJSamqrMzMyI8Tk5OQoEApKkQCAQEWD61vet609lZaVcLld4mTBhgtm2YyYjIyNqffTo0XHuBACA5GY6xPzDP/yDDhw4oL1792rJkiUqKyvT66+/PhS9ha1cuVIdHR3hpbm5eUi/73yOHDkStX706NH4NgIAQJIzfYt1amqqCgoKJElTp05VXV2dfv7zn+vrX/+6enp61N7eHnE0prW1VW63W5Lkdru1b9++iM/ru3upb0w0aWlpSktLM9sqAAC4iF3wE3tDoZC6u7s1depUjRgxQjt37gyvO3z4sJqamsKP5Pf5fDp48KDa2trCY3bs2CGn06mioqILbSUueO0AAADDg6kjMStXrtR1112nvLw8nThxQps2bdIf/vAHPffcc3K5XCovL9eKFSuUlZUlp9OpO++8Uz6fT7NmzZIkXXPNNSoqKtKiRYu0evVqBQIB3XfffaqoqLDMkRaPxyOfz6c9e/aEa7NmzeLOJAAA4sxUiGlra9Ntt92mY8eOyeVy6YorrtBzzz2nf/7nf5YkPfLII7Lb7VqwYIG6u7tVUlKixx57LLy9w+FQTU2NlixZIp/Pp9GjR6usrEwPPvhgbPdqCNXV1UUEGEnas2eP6urqNH369AR1BQBA8uHdSSaVl5frV7/61Tn1f/u3f9MTTzwR114AALCSYfOcmGR17NixqPWWlpY4dwIAQHIjxJg0Z84cU3UAADA0CDEm9V3/c7aPPqkYAAAMPUKMSZ2dnVHrJ0+ejHMnAAAkN0KMSbx2AACA4YEQYxKvHQAAYHggxJj03nvvmaoDAIChQYgxaezYsabqAABgaBBiTMrPz49anzhxYnwbAQAgyRFiTOLuJAAAhgdCjEmFhYXn1Gw2mwoKChLQDQAAyYsQY1K01w4YhtHv6wgAAMDQIMSY9NJLL0Wtv/LKK3HuBACA5EaIMenzn/981Prs2bPj3AkAAMmNEAMAACyJEGMSp5MAABgeCDEmcToJAIDhgRBj0vTp01VWVhZRKysr0/Tp0xPUEQAAyclmGIaR6CbMCgaDcrlc6ujokNPpTEgPdXV1euWVVzR79mwCDAAAAxDr3++UGPSUlLZt26ann35ax48fJ8QAAJAAHIkZhDFjxkS8fiAjI0MnTpyIex8AAFhJrH+/uSbGpFWrVp3z/qTOzk6tWrUqQR0BAJCcCDEmPf3001HrW7dujXMnAAAkN0KMSfPnz49a/8pXvhLnTgAASG5cEzMII0aM0OnTp8N/p6Sk6NSpU3HvAwAAK+GamASrq6uLCDCSdPr0adXV1SWoIwAAkhMhxiReOwAAwPBAiDGJ1w4AADA8EGJMGj9+vGw2W0TNZrNp/PjxCeoIAIDkRIgxqaGhQWdfC20YhhobGxPUEQAAyYkQY1JhYaHs9shpczgcKigoSFBHAAAkJ0KMSR6PR1VVVXI4HJLOBJh169bJ4/EkuDMAAJILIWaQQqFQxP8FAADxxcPuTPL7/fJ6vRHhxeFw6OjRoxyNAQDgPHjYXYI1NDScc/Slt7eXC3sBAIgzQoxJXNgLAMDwQIgxqe/C3r5nxdhsNi7sBQAgAQgxg/DSSy+FnxVjGEa/ryIAAABDx1SIqays1PTp0zVmzBhlZ2frxhtv1OHDhyPGdHV1qaKiQmPHjlVGRoYWLFig1tbWiDFNTU0qLS3VqFGjlJ2drbvvvvuclyoOV3V1ddq4cWNEbePGjbwAEgCAODMVYnbv3q2Kigq9+uqr2rFjh06dOqVrrrlGJ0+eDI9Zvny5tm3bpi1btmj37t1qaWnR/Pnzw+t7e3tVWlqqnp4e7dmzRxs3btSGDRu0atWq2O3VEOIFkAAADA8XdIv1u+++q+zsbO3evVtf+MIX1NHRoXHjxmnTpk266aabJElvvPGGJk+erNraWs2aNUvbt2/XvHnz1NLSopycHEnS2rVrdc899+jdd99Vamrqx35vIm+xrqmp0fXXX39Ofdu2bZo3b15cewEAwEqG1S3WHR0dkqSsrCxJUn19vU6dOqXi4uLwmEmTJikvL0+1tbWSpNraWk2ZMiUcYCSppKREwWBQhw4dupB24mL06NFR6xkZGXHuBACA5JYy2A1DoZCWLVum2bNn6/LLL5ckBQIBpaamKjMzM2JsTk6OAoFAeMxHA0zf+r510XR3d6u7uzv8dzAYHGzbF6y/sNJfuAEAAENj0EdiKioq9Nprr2nz5s2x7CeqyspKuVyu8DJhwoQh/87+dHZ2Rq1/9LogAAAw9AYVYpYuXaqamhrt2rUr4vkobrdbPT09am9vjxjf2toqt9sdHnP23Up9f/eNOdvKlSvV0dERXpqbmwfTdkz0F1b6CzcAAGBomAoxhmFo6dKl2rp1q1544QXl5+dHrJ86dapGjBihnTt3hmuHDx9WU1OTfD6fJMnn8+ngwYNqa2sLj9mxY4ecTqeKioqifm9aWpqcTmfEkij79u2LWt+/f3+cOwEAILmZuiamoqJCmzZt0m9/+1uNGTMmfA2Ly+VSenq6XC6XysvLtWLFCmVlZcnpdOrOO++Uz+fTrFmzJEnXXHONioqKtGjRIq1evVqBQED33XefKioqlJaWFvs9jLHx48dHrfd3FAkAAAwNUyHm8ccflyR98YtfjKivX79et99+uyTpkUcekd1u14IFC9Td3a2SkhI99thj4bEOh0M1NTVasmSJfD6fRo8erbKyMj344IMXtidxMm3atKj1qVOnxrkTAACSm6kQM5BHyowcOVJr1qzRmjVr+h3j9Xr1+9//3sxXDxv9nTaqr6/X9OnT49wNAADJi3cnmVRfX2+qDgAAhgYhxqQLeMAxAACIIUKMSZdeemnU+qc+9ak4dwIAQHIjxAAAAEsixJjU1dUVtf7R1yIAAIChR4gxqb/TRhMnToxvIwAAJDlCjEnHjx+PWj/7VQsAAGBoEWJMuuyyy6LWCwoK4twJAADJjRBj0gcffBC1/uGHH8a5EwAAkhshxqTGxkZTdQAAMDQIMSZxdxIAAMMDIcYk7k4CAGB4IMSYdODAgaj1v/zlL/FtBACAJEeIAQAAlkSIMam4uDhqfe7cuXHuBACA5EaIMYlbrAEAGB4IMQAAwJIIMSaNGjUqaj09PT3OnQAAkNwIMSbt27cvan3//v1x7gQAgORGiDFp/PjxUetutzvOnQAAkNwIMSZNmzYtan3q1Klx7gQAgORGiDGpv9NG9fX1ce4EAIDkRogx6dixY1HrgUAgzp0AAJDcCDEmzZgxI2q9v9NMAABgaBBiTOJhdwAADA+EGJPee+89U3UAADA0CDEAAMCSCDEmvf/++6bqAABgaBBiTHrrrbdM1QEAwNCwGYZhJLoJs4LBoFwulzo6OuR0OuP63aNHj456ce+oUaN08uTJuPYCAICVxPr3myMxJvV3d1J/dQAAMDQIMQAAwJIIMSZNmDDBVB0AAAwNQoxJt9xyS9T6v/zLv8S5EwAAkhshxqS0tLSo9ZEjR8a5EwAAkhshxqTrr78+ar20tDTOnQAAkNwIMSaNHz/eVB0AAAwNQoxJe/bsiVqvra2NcycAACQ3QoxJvAASAIDhwXSIefHFF3X99dcrNzdXNptNzzzzTMR6wzC0atUqjR8/Xunp6SouLlZDQ0PEmOPHj2vhwoVyOp3KzMxUeXm5Ojs7L2hH4uXgwYNR63/5y1/i3AkAAMnNdIg5efKkPvOZz2jNmjVR169evVqPPvqo1q5dq71792r06NEqKSlRV1dXeMzChQt16NAh7dixQzU1NXrxxRe1ePHiwe9FHNXX10et//GPf4xzJwAAJLcLeneSzWbT1q1bdeONN0o6cxQmNzdX3/nOd/Td735XktTR0aGcnBxt2LBBN998s/7617+qqKhIdXV1mjZtmiTp2Wef1Ze+9CX5/X7l5uZ+7Pcm8t1J+fn5Onr06Dn1iRMn6siRI3HtBQAAKxnW7046cuSIAoGAiouLwzWXy6WZM2eGL3ytra1VZmZmOMBIUnFxsex2u/bu3Rv1c7u7uxUMBiOWROnv2pfjx4/HuRMAAJJbTENMIBCQJOXk5ETUc3JywusCgYCys7Mj1qekpCgrKys85myVlZVyuVzhJZGP+B87dmzUelZWVpw7AQAguVni7qSVK1eqo6MjvDQ3Nyesl97e3qj1UCgU504AAEhuMQ0xbrdbktTa2hpRb21tDa9zu91qa2uLWH/69GkdP348POZsaWlpcjqdEUuinDhxwlQdAAAMjZiGmPz8fLndbu3cuTNcCwaD2rt3r3w+nyTJ5/Opvb094i6fF154QaFQSDNnzoxlO0MiPT09an3UqFFx7gQAgOSWYnaDzs5ONTY2hv8+cuSIDhw4oKysLOXl5WnZsmX60Y9+pMLCQuXn5+v+++9Xbm5u+A6myZMn69prr9Udd9yhtWvX6tSpU1q6dKluvvnmAd2ZlGgjRowwVQcAAEPDdIjZv3+//umf/in894oVKyRJZWVl2rBhg773ve/p5MmTWrx4sdrb2zVnzhw9++yzEW95fuqpp7R06VJdffXVstvtWrBggR599NEY7M7Q83q9ampqOqeeyIuNAQBIRhf0nJhESeRzYm6++Wb9+te/Pqd+yy23aNOmTXHtBQAAKxnWz4lJBv09y4YXQAIAEF+EGJPeeeedqPVjx47FuRMAAJIbIcakzMzMqPVE3vYNAEAyIsSY5HA4TNUBAMDQIMSY1NnZGbV+8uTJOHcCAEByI8SY9OGHH0atf/DBB3HuBACA5EaIMam/dyf1VwcAAEODEGOS3R59yvqrAwCAocEvr0kul8tUHQAADA1CjEmnT582VQcAAEODEGNSV1eXqToAABgahBiTTp06ZaoOAACGBiEGAABYEiEGAABYEiEGAABYEiEGAABYEiEGAABYEiEGAABYEiEGAABYEiEGAABYEiEGAABYEiEGAABYEiEGAABYEiEGAABYEiEGAABYEiEGAABYEiEGAABYEiEGAABYEiEGAABYEiEGAABYEiEGAABYEiEmhmw2W6JbAAAgaRBiAACAJRFiTJo4cWKiWwAAACLEmHbkyJFEtwAAAESIAQAAFkWIAQAAlkSIAQAAlpTQELNmzRpNnDhRI0eO1MyZM7Vv375EtgMAACwkJVFf/Otf/1orVqzQ2rVrNXPmTP3sZz9TSUmJDh8+rOzs7ES1dcHPehnqZ8WkpKTI4XAoJSVFqampSk9PlySlpaXp+PHj+uQnP6mCggK1tbVp5MiRmjBhgpqbmyVJEyZMkCR97Wtf07x58+T3+7Vt27bwnF9yySV6//331dXVpRkzZmj06NE6efKk3nzzTV122WUaPXq0CgsL5fF4BtSr3+9XQ0NDeBu/3689e/ZIkvLz89XZ2Rmxrm+spIjtzv4sSeHPueqqqz62n4/77IH0bsaFbHsxOd889LeOeb949gPWZpl/h0aCzJgxw6ioqAj/3dvba+Tm5hqVlZUfu21HR4chyejo6IhpT5KSZrn00ksHtZ3dbjd++ctffuxc/vKXvzTsdnt4m7KyMsNms0X9vLKysvBYm80WHtf3XR/9rI+u7/v7fP30t+359uPs3geyv7HY9mJyvnnobx3zfvHsB6xtKP8dxvr3OyEhpru723A4HMbWrVsj6rfddpvx5S9/+ZzxXV1dRkdHR3hpbm6OeYhJdKiw0uJwOIzm5uZ+57K5uTn8X4BYfFe08HN2EIrWz8f1EW0/om3zcfsbi20vJuebh/7W7du3L+nn/WLZD1jbUP87jHWIScg1MX//+9/V29urnJyciHpOTo4CgcA54ysrK+VyucJL32kRJEZvb68aGxv7Xd/Q0KBQKBSz7zIM47xjQqFQ1H4+ro9o+xFtm4/b31hsezE53zz0t+7ll19O+nm/WPYD1ma1f4eWuDtp5cqV6ujoCC9913ggMRwOhwoKCvpdX1hYKLs9Nv+0HA7Hx15nZLfbo/bzcX1E249o23zc/sZi24vJ+eahv3Vz5sxJ+nm/WPYD1ma1f4cJCTGf+MQn5HA41NraGlFvbW2V2+0+Z3xaWpqcTmfEEmsf9//tX2wuvfTSQV2E7HA4tG7duvNe6OXxeFRVVSWHwxHepqysLOr39a3rG2u328Pj+r7riSeeCK+32WwRn2Oz2VRVVRW1n7P7iPbZZ28XrfeP299YbHsxOd889Ldu+vTpST/vF8t+wNqs9u/QZiTo13vmzJmaMWOGfvGLX0g6c0ogLy9PS5cu1b333nvebYPBoFwulzo6OmIeaIb7m6g/endSWlqa0tPTZRiG0tLS9P777ys3N1cFBQX6+9//rrS0NHk8Hr3zzjsyDEMej0d2u1033XRT+O6kmpoavfnmmxo3blz47qTu7m5NmzZNGRkZ6uzsVGNjowoKCpSRkaGCggJTdyf1bdt3B1Jtba2kM++gOnnyZMS6vrGSIrY7+7MkhT/H5/MN6O6k8332QHo340K2vZicbx76W8e8Xzz7AWsbqn+Hsf79TliI+fWvf62ysjKtW7dOM2bM0M9+9jP95je/0RtvvHHOtTJnG8oQAwAAhkasf78T9pyYr3/963r33Xe1atUqBQIBffazn9Wzzz77sQEGAABASuCRmAvBkRgAAKwn1r/flrg7CQAA4GyEGAAAYEmEGAAAYEmEGAAAYEmEGAAAYEmEGAAAYEmEGAAAYEmEGAAAYEmEGAAAYEkJe+3Aheh7yHAwGExwJwAAYKD6frdj9bIAS4aYEydOSJImTJiQ4E4AAIBZJ06ckMvluuDPseS7k0KhkFpaWjRmzBjZbLaE9BAMBjVhwgQ1Nzfz/qY4YL7ji/mOL+Y7vpjv+ProfI8ZM0YnTpxQbm6u7PYLv6LFkkdi7Ha7PB5PotuQJDmdTv5LEEfMd3wx3/HFfMcX8x1fffMdiyMwfbiwFwAAWBIhBgAAWBIhZpDS0tL0wAMPKC0tLdGtJAXmO76Y7/hivuOL+Y6voZxvS17YCwAAwJEYAABgSYQYAABgSYQYAABgSYQYAABgSYSYQVqzZo0mTpyokSNHaubMmdq3b1+iW7ooVFZWavr06RozZoyys7N144036vDhwxFjurq6VFFRobFjxyojI0MLFixQa2trgjq+eDz88MOy2WxatmxZuMZcx9Y777yjW2+9VWPHjlV6erqmTJmi/fv3h9cbhqFVq1Zp/PjxSk9PV3FxsRoaGhLYsXX19vbq/vvvV35+vtLT03XppZfqhz/8YcQ7e5jvwXvxxRd1/fXXKzc3VzabTc8880zE+oHM7fHjx7Vw4UI5nU5lZmaqvLxcnZ2d5hoxYNrmzZuN1NRU41e/+pVx6NAh44477jAyMzON1tbWRLdmeSUlJcb69euN1157zThw4IDxpS99ycjLyzM6OzvDY775zW8aEyZMMHbu3Gns37/fmDVrlnHVVVclsGvr27dvnzFx4kTjiiuuMO66665wnbmOnePHjxter9e4/fbbjb179xpvvfWW8dxzzxmNjY3hMQ8//LDhcrmMZ555xvjzn/9sfPnLXzby8/ONDz/8MIGdW9OPf/xjY+zYsUZNTY1x5MgRY8uWLUZGRobx85//PDyG+R683//+98b3v/994+mnnzYkGVu3bo1YP5C5vfbaa43PfOYzxquvvmq89NJLRkFBgXHLLbeY6oMQMwgzZswwKioqwn/39vYaubm5RmVlZQK7uji1tbUZkozdu3cbhmEY7e3txogRI4wtW7aEx/z1r381JBm1tbWJatPSTpw4YRQWFho7duww/vEf/zEcYpjr2LrnnnuMOXPm9Ls+FAoZbrfb+MlPfhKutbe3G2lpacZ///d/x6PFi0ppaanxjW98I6I2f/58Y+HChYZhMN+xdHaIGcjcvv7664Yko66uLjxm+/bths1mM955550Bfzenk0zq6elRfX29iouLwzW73a7i4mLV1tYmsLOLU0dHhyQpKytLklRfX69Tp05FzP+kSZOUl5fH/A9SRUWFSktLI+ZUYq5j7Xe/+52mTZumr371q8rOztaVV16pJ554Irz+yJEjCgQCEfPtcrk0c+ZM5nsQrrrqKu3cuVNvvvmmJOnPf/6zXn75ZV133XWSmO+hNJC5ra2tVWZmpqZNmxYeU1xcLLvdrr179w74uyz5AshE+vvf/67e3l7l5ORE1HNycvTGG28kqKuLUygU0rJlyzR79mxdfvnlkqRAIKDU1FRlZmZGjM3JyVEgEEhAl9a2efNm/fGPf1RdXd0565jr2Hrrrbf0+OOPa8WKFfqP//gP1dXV6dvf/rZSU1NVVlYWntNo/9vCfJt37733KhgMatKkSXI4HOrt7dWPf/xjLVy4UJKY7yE0kLkNBALKzs6OWJ+SkqKsrCxT80+IwbBVUVGh1157TS+//HKiW7koNTc366677tKOHTs0cuTIRLdz0QuFQpo2bZoeeughSdKVV16p1157TWvXrlVZWVmCu7v4/OY3v9FTTz2lTZs26dOf/rQOHDigZcuWKTc3l/m+iHA6yaRPfOITcjgc59yh0draKrfbnaCuLj5Lly5VTU2Ndu3aJY/HE6673W719PSovb09Yjzzb159fb3a2tr0uc99TikpKUpJSdHu3bv16KOPKiUlRTk5Ocx1DI0fP15FRUURtcmTJ6upqUmSwnPK/7bExt133617771XN998s6ZMmaJFixZp+fLlqqyslMR8D6WBzK3b7VZbW1vE+tOnT+v48eOm5p8QY1JqaqqmTp2qnTt3hmuhUEg7d+6Uz+dLYGcXB8MwtHTpUm3dulUvvPCC8vPzI9ZPnTpVI0aMiJj/w4cPq6mpifk36eqrr9bBgwd14MCB8DJt2jQtXLgw/J+Z69iZPXv2OY8LePPNN+X1eiVJ+fn5crvdEfMdDAa1d+9e5nsQPvjgA9ntkT9xDodDoVBIEvM9lAYytz6fT+3t7aqvrw+PeeGFFxQKhTRz5syBf9kFX5achDZv3mykpaUZGzZsMF5//XVj8eLFRmZmphEIBBLdmuUtWbLEcLlcxh/+8Afj2LFj4eWDDz4Ij/nmN79p5OXlGS+88IKxf/9+w+fzGT6fL4FdXzw+eneSYTDXsbRv3z4jJSXF+PGPf2w0NDQYTz31lDFq1CjjySefDI95+OGHjczMTOO3v/2t8Ze//MW44YYbuOV3kMrKyoxPfvKT4Vusn376aeMTn/iE8b3vfS88hvkevBMnThh/+tOfjD/96U+GJOOnP/2p8ac//cl4++23DcMY2Nxee+21xpVXXmns3bvXePnll43CwkJusY6XX/ziF0ZeXp6RmppqzJgxw3j11VcT3dJFQVLUZf369eExH374ofGtb33LuOSSS4xRo0YZX/nKV4xjx44lrumLyNkhhrmOrW3bthmXX365kZaWZkyaNMmoqqqKWB8KhYz777/fyMnJMdLS0oyrr77aOHz4cIK6tbZgMGjcddddRl5enjFy5EjjU5/6lPH973/f6O7uDo9hvgdv165dUf+3uqyszDCMgc3te++9Z9xyyy1GRkaG4XQ6jX/91381Tpw4YaoPm2F85PGFAAAAFsE1MQAAwJIIMQAAwJIIMQAAwJIIMQAAwJIIMQAAwJIIMQAAwJIIMQAAwJIIMQAAwJIIMQAAwJIIMQAAwJIIMQAAwJIIMQAAwJL+D3eDwdP/B/96AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "rv = reciprocal(3e-4, 3e-2)\n",
    "ax.plot(X_train_scaled, rv.pdf(X_train_scaled), 'k.', lw=2, label='frozen pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1137 - val_loss: 6.7088\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6457 - val_loss: 14.2003\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8177 - val_loss: 15.9503\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8587 - val_loss: 13.5527\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8540 - val_loss: 22.0748\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8677 - val_loss: 19.7165\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8633 - val_loss: 18.0925\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2995 - val_loss: 8.5474\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8136 - val_loss: 27.8328\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 8.1763 - val_loss: 15.6510\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.8148 - val_loss: 6.0229\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6183 - val_loss: 1.8199\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8775 - val_loss: 0.6632\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5577 - val_loss: 0.8086\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5583 - val_loss: 0.8554\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5538 - val_loss: 1.7806\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6128 - val_loss: 13.7213\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.0299 - val_loss: 5.6878\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7404 - val_loss: 9.8422\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.6367 - val_loss: 3.2109\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6162 - val_loss: 2.0631\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8655 - val_loss: 2.7989\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5880 - val_loss: 1.5643\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6421 - val_loss: 0.6030\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5929 - val_loss: 0.6731\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7487 - val_loss: 1.8940\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 1.3214\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5900 - val_loss: 0.5677\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7693 - val_loss: 1.0991\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5439 - val_loss: 1.4055\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2324 - val_loss: 2.6473\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3699 - val_loss: 1.8969\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3167 - val_loss: 1.8065\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4616 - val_loss: 2.6066\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5578 - val_loss: 2.7342\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7059 - val_loss: 3.0798\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8402 - val_loss: 3.6580\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.9203 - val_loss: 4.2373\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.3373 - val_loss: 5.6068\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.3437 - val_loss: 3.7824\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.1894 - val_loss: 4.4128\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6043 - val_loss: 1.2342\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5793 - val_loss: 2.7176\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8137 - val_loss: 0.7789\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5717 - val_loss: 0.5586\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5567 - val_loss: 0.7042\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5375 - val_loss: 1.1631\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6742 - val_loss: 0.7192\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5812 - val_loss: 4.0052\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6738 - val_loss: 7.6533\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6536 - val_loss: 5.9842\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6516 - val_loss: 4.2108\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6815 - val_loss: 6.2507\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8189 - val_loss: 5.5051\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7539 - val_loss: 12.5235\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7287 - val_loss: 21.0337\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6.7977 - val_loss: 8.9713\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6970 - val_loss: 12.5980\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.6665 - val_loss: 4.7026\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.6557 - val_loss: 2.3930\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6412 - val_loss: 0.7018\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5563 - val_loss: 2.6910\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0084 - val_loss: 0.7550\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5722 - val_loss: 0.7029\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5971 - val_loss: 0.5969\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5183 - val_loss: 0.5363\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5818 - val_loss: 2.5172\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1464 - val_loss: 1.0493\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5543 - val_loss: 3.7964\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6267 - val_loss: 2.0462\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5749 - val_loss: 25.6592\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8955 - val_loss: 16.2900\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6.0474 - val_loss: 10.0258\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4216 - val_loss: 9.3255\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0524 - val_loss: 8.3136\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.6731 - val_loss: 7.7981\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6341 - val_loss: 4.9825\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7029 - val_loss: 0.9301\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7575 - val_loss: 1.4964\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0529 - val_loss: 1.4505\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0186 - val_loss: 1.6352\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3222 - val_loss: 2.8175\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5688 - val_loss: 0.8928\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5769 - val_loss: 0.5370\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6028 - val_loss: 0.6162\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5618 - val_loss: 1.4006\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6503 - val_loss: 2.9301\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6223 - val_loss: 9.2878\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7139 - val_loss: 5.3453\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.9196 - val_loss: 2.1517\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5957 - val_loss: 8.0817\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.9018 - val_loss: 4.1342\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4708 - val_loss: 1.2464\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6654 - val_loss: 0.5981\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6711 - val_loss: 2.0282\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7737 - val_loss: 1.0195\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5486 - val_loss: 0.7069\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5844 - val_loss: 0.6552\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5825 - val_loss: 0.9527\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5521 - val_loss: 0.8101\n",
      "121/121 [==============================] - 0s 887us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.8275 - val_loss: 8.3244\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5153 - val_loss: 128.5457\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6.5376 - val_loss: 1549.2725\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 132.5451 - val_loss: 21625.7344\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2508.1384 - val_loss: 291786.0625\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 13216.9443 - val_loss: 3953095.5000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 416714.6875 - val_loss: 52893188.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4009584.0000 - val_loss: 712008640.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 53087456.0000 - val_loss: 9551125504.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 540132672.0000 - val_loss: 128815751168.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5371236352.0000 - val_loss: 1737506029568.0000\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 203165188096.0000 - val_loss: 23467145560064.0000\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1812679753728.0000 - val_loss: 315831628070912.0000\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 35207587561472.0000 - val_loss: 4229685403713536.0000\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 442849715814400.0000 - val_loss: 56928911040184320.0000\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2475838998052864.0000 - val_loss: 773031853434077184.0000\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 76458947673849856.0000 - val_loss: 10329590685560209408.0000\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 464815104668467200.0000 - val_loss: 139610946333694754816.0000\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 10145403796210057216.0000 - val_loss: 1866678713675310694400.0000\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 201413975961495404544.0000 - val_loss: 25068735634803513098240.0000\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1449280596610985754624.0000 - val_loss: 337540288471791304704000.0000\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 19367622111115761156096.0000 - val_loss: 4519600736702558277468160.0000\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 472333817952524667191296.0000 - val_loss: 60758363773598440074772480.0000\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5046994014461042813304832.0000 - val_loss: 815226774517293428047347712.0000\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 84517724023676158282301440.0000 - val_loss: 10931851033676528966814400512.0000\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 550327139293734723968303104.0000 - val_loss: 146810808721311712522176299008.0000\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 7034557533227936686274510848.0000 - val_loss: 1975641685986972180169516646400.0000\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 90234345957564476210844532736.0000 - val_loss: 26603940742855907880686231486464.0000\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2555108241085024887391792398336.0000 - val_loss: 358021466540374160516621287817216.0000\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 18482351699242617177797472288768.0000 - val_loss: 4836685274394679826727767730290688.0000\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 397607964946006001934143166873600.0000 - val_loss: 64803066206491443940281905315840000.0000\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6416321832808620586449616947380224.0000 - val_loss: inf\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf              \n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf               \n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf          \n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf            \n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 800us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tmoia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tmoia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tmoia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tmoia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scikeras\\wrappers.py\", line 1117, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tmoia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scikeras\\wrappers.py\", line 1714, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tmoia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tmoia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py\", line 989, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tmoia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py\", line 101, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tmoia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\tmoia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"C:\\Users\\tmoia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.4450 - val_loss: 0.8247\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5642 - val_loss: 0.9112\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5397 - val_loss: 0.5995\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5232 - val_loss: 0.5450\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5150 - val_loss: 0.5458\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5109 - val_loss: 0.5596\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5065 - val_loss: 0.7514\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5103 - val_loss: 0.5988\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5068 - val_loss: 0.6764\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5103 - val_loss: 0.5318\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5053 - val_loss: 0.6258\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5062 - val_loss: 0.6729\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5056 - val_loss: 0.8253\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5128 - val_loss: 0.5307\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5023 - val_loss: 0.8609\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5114 - val_loss: 0.5972\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5050 - val_loss: 0.7395\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5112 - val_loss: 0.5431\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5028 - val_loss: 0.8436\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5121 - val_loss: 0.5636\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5055 - val_loss: 0.6333\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5071 - val_loss: 0.6343\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5095 - val_loss: 0.5344\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5042 - val_loss: 0.7126\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5095 - val_loss: 0.5617\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5070 - val_loss: 0.5322\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5074 - val_loss: 0.5323\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5070 - val_loss: 0.5356\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5082 - val_loss: 0.5409\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5073 - val_loss: 0.5437\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5050 - val_loss: 0.6943\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5091 - val_loss: 0.5985\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5076 - val_loss: 0.5345\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5037 - val_loss: 0.6994\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5100 - val_loss: 0.5755\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5045 - val_loss: 0.7720\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5094 - val_loss: 0.6119\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5075 - val_loss: 0.6003\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5084 - val_loss: 0.5452\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5074 - val_loss: 0.5485\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5030 - val_loss: 0.8218\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5116 - val_loss: 0.5312\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5077 - val_loss: 0.5310\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5074 - val_loss: 0.5316\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5072 - val_loss: 0.5349\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5075 - val_loss: 0.5375\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5071 - val_loss: 0.5353\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5027 - val_loss: 0.8910\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5128 - val_loss: 0.5342\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5053 - val_loss: 0.6837\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5063 - val_loss: 0.7672\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5064 - val_loss: 0.7952\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5107 - val_loss: 0.5523\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5085 - val_loss: 0.5591\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5077 - val_loss: 0.5340\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5066 - val_loss: 0.5373\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5076 - val_loss: 0.5428\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5075 - val_loss: 0.5455\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5058 - val_loss: 0.6545\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5065 - val_loss: 0.7088\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5102 - val_loss: 0.5595\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5076 - val_loss: 0.5342\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5051 - val_loss: 0.6513\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5089 - val_loss: 0.5332\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5070 - val_loss: 0.5343\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5066 - val_loss: 0.5580\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5064 - val_loss: 0.6344\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5065 - val_loss: 0.6424\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5094 - val_loss: 0.5327\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5045 - val_loss: 0.6418\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5078 - val_loss: 0.6335\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5047 - val_loss: 0.8208\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5125 - val_loss: 0.5345\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5069 - val_loss: 0.5462\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5060 - val_loss: 0.6447\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5074 - val_loss: 0.6221\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5090 - val_loss: 0.5539\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5043 - val_loss: 0.6694\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5090 - val_loss: 0.5986\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5038 - val_loss: 0.8287\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5123 - val_loss: 0.5411\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5077 - val_loss: 0.5388\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5055 - val_loss: 0.6425\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5097 - val_loss: 0.5342\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5065 - val_loss: 0.5539\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5074 - val_loss: 0.5347\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5033 - val_loss: 0.7871\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5119 - val_loss: 0.5368\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5027 - val_loss: 0.8476\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5100 - val_loss: 0.6589\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5061 - val_loss: 0.7195\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5098 - val_loss: 0.5286\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5072 - val_loss: 0.5377\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5068 - val_loss: 0.5782\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5079 - val_loss: 0.5391\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5080 - val_loss: 0.5311\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5029 - val_loss: 0.8645\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5137 - val_loss: 0.5388\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5076 - val_loss: 0.5359\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5074 - val_loss: 0.5394\n",
      "121/121 [==============================] - 0s 762us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9509 - val_loss: 6.8507\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8035 - val_loss: 0.7467\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5034 - val_loss: 1.9251\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4840 - val_loss: 0.6054\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5088 - val_loss: 0.5423\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4271 - val_loss: 0.4326\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4145 - val_loss: 0.4941\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4031 - val_loss: 0.4148\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3964 - val_loss: 0.4392\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3918 - val_loss: 0.4050\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3881 - val_loss: 0.4215\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3863 - val_loss: 0.3949\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3856 - val_loss: 0.4203\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3801 - val_loss: 0.3973\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3775 - val_loss: 0.4028\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3750 - val_loss: 0.4017\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3737 - val_loss: 0.3849\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3731 - val_loss: 0.3900\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3736 - val_loss: 0.4214\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3716 - val_loss: 0.3884\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3694 - val_loss: 0.3957\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3650 - val_loss: 0.3930\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3650 - val_loss: 0.3830\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3619 - val_loss: 0.3981\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3599 - val_loss: 0.3957\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3592 - val_loss: 0.3929\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3583 - val_loss: 0.3722\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3603 - val_loss: 0.4423\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3571 - val_loss: 0.3699\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3583 - val_loss: 0.4459\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3662 - val_loss: 0.3670\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3549 - val_loss: 0.3908\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3501 - val_loss: 0.3640\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3495 - val_loss: 0.3691\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3481 - val_loss: 0.3696\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3466 - val_loss: 0.3577\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3504 - val_loss: 0.3623\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3448 - val_loss: 0.3826\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3430 - val_loss: 0.3753\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3439 - val_loss: 0.3768\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3428 - val_loss: 0.3618\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3410 - val_loss: 0.3648\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3428 - val_loss: 0.3615\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3376 - val_loss: 0.3787\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3367 - val_loss: 0.3877\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3348 - val_loss: 0.3550\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3340 - val_loss: 0.3484\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3360 - val_loss: 0.3774\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3340 - val_loss: 0.4143\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3445 - val_loss: 0.4347\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3383 - val_loss: 0.3466\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3315 - val_loss: 0.3738\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3329 - val_loss: 0.3451\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3286 - val_loss: 0.3748\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3277 - val_loss: 0.3531\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3268 - val_loss: 0.3436\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3278 - val_loss: 0.3440\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3248 - val_loss: 0.3601\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3258 - val_loss: 0.3399\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3220 - val_loss: 0.3741\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3216 - val_loss: 0.3428\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3217 - val_loss: 0.3365\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3200 - val_loss: 0.3418\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3205 - val_loss: 0.3364\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3177 - val_loss: 0.3468\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3184 - val_loss: 0.3382\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3172 - val_loss: 0.3423\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3164 - val_loss: 0.3425\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3161 - val_loss: 0.3655\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3173 - val_loss: 0.3421\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3159 - val_loss: 0.3369\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3171 - val_loss: 0.3323\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3140 - val_loss: 0.3378\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3132 - val_loss: 0.3387\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3135 - val_loss: 0.3330\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3117 - val_loss: 0.3374\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3107 - val_loss: 0.3430\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3128 - val_loss: 0.3415\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3129 - val_loss: 0.3395\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3105 - val_loss: 0.3596\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3445 - val_loss: 0.3681\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3122 - val_loss: 0.3264\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3102 - val_loss: 0.4025\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3106 - val_loss: 0.3494\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3087 - val_loss: 0.3739\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3083 - val_loss: 0.3462\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3081 - val_loss: 0.3324\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3064 - val_loss: 0.4045\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3080 - val_loss: 0.4272\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3080 - val_loss: 0.4296\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3134 - val_loss: 0.3331\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3093 - val_loss: 0.3886\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3067 - val_loss: 0.3262\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3051 - val_loss: 0.3453\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3048 - val_loss: 0.3197\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3050 - val_loss: 0.3392\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3039 - val_loss: 0.3220\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3038 - val_loss: 0.3428\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3030 - val_loss: 0.3293\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3030 - val_loss: 0.3378\n",
      "121/121 [==============================] - 0s 711us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.4743 - val_loss: 30.6332\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2810 - val_loss: 203.3620\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6851 - val_loss: 1162.7542\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.4346 - val_loss: 0.5955\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3826 - val_loss: 0.6078\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6507 - val_loss: 0.4950\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4593 - val_loss: 0.4208\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4315 - val_loss: 0.4041\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5363 - val_loss: 0.6463\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4324 - val_loss: 0.4264\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4186 - val_loss: 0.3975\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3692 - val_loss: 0.3864\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3627 - val_loss: 0.3861\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3631 - val_loss: 0.3842\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3533 - val_loss: 0.3774\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3497 - val_loss: 0.3801\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3473 - val_loss: 0.3694\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3435 - val_loss: 0.3729\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3418 - val_loss: 0.3757\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3390 - val_loss: 0.3754\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3390 - val_loss: 0.3637\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3357 - val_loss: 0.3670\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3334 - val_loss: 0.3608\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3312 - val_loss: 0.3634\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3316 - val_loss: 0.3629\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3299 - val_loss: 0.3617\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3266 - val_loss: 0.3601\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3339 - val_loss: 0.3598\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3258 - val_loss: 0.3624\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3254 - val_loss: 0.3607\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3239 - val_loss: 0.3478\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3259 - val_loss: 0.3606\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3208 - val_loss: 0.3509\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3206 - val_loss: 0.3523\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3193 - val_loss: 0.3667\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3182 - val_loss: 0.3507\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3181 - val_loss: 0.3528\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3162 - val_loss: 0.3516\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3143 - val_loss: 0.3506\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3131 - val_loss: 0.3440\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3135 - val_loss: 0.3490\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3138 - val_loss: 0.3505\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3124 - val_loss: 0.3535\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3124 - val_loss: 0.3417\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3127 - val_loss: 0.3584\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3112 - val_loss: 0.3402\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3087 - val_loss: 0.3481\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3156 - val_loss: 0.3362\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3096 - val_loss: 0.3677\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3090 - val_loss: 0.3323\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3086 - val_loss: 0.3338\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3068 - val_loss: 0.3641\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3062 - val_loss: 0.3320\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3048 - val_loss: 0.3296\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3050 - val_loss: 0.3738\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3055 - val_loss: 0.3288\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3032 - val_loss: 0.3289\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3106 - val_loss: 0.3251\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3048 - val_loss: 0.3802\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3037 - val_loss: 0.3253\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3021 - val_loss: 0.3248\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3020 - val_loss: 0.3257\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3015 - val_loss: 0.3248\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3018 - val_loss: 0.3802\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3003 - val_loss: 0.3263\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3005 - val_loss: 0.3288\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3022 - val_loss: 0.3250\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3167 - val_loss: 0.3887\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3012 - val_loss: 0.3214\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3005 - val_loss: 0.3231\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2987 - val_loss: 0.3232\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2973 - val_loss: 0.3238\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2982 - val_loss: 0.3217\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2971 - val_loss: 0.3844\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2972 - val_loss: 0.3197\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2962 - val_loss: 0.3264\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2976 - val_loss: 0.3250\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2972 - val_loss: 0.3181\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3007 - val_loss: 0.3188\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2945 - val_loss: 0.3499\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2947 - val_loss: 0.3180\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2952 - val_loss: 0.3240\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2945 - val_loss: 0.3395\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3273 - val_loss: 0.3209\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2937 - val_loss: 0.4015\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2961 - val_loss: 0.3211\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2936 - val_loss: 0.3189\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2931 - val_loss: 0.3204\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2917 - val_loss: 0.3152\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2918 - val_loss: 0.3199\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2923 - val_loss: 0.3217\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3151 - val_loss: 0.3163\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2947 - val_loss: 0.3207\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2928 - val_loss: 0.3257\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2905 - val_loss: 0.3561\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2911 - val_loss: 0.3191\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2900 - val_loss: 0.3148\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2900 - val_loss: 0.3893\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2913 - val_loss: 0.3258\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2902 - val_loss: 0.3173\n",
      "121/121 [==============================] - 0s 755us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8434 - val_loss: 0.9602\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5177 - val_loss: 1.0532\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4546 - val_loss: 0.4656\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4280 - val_loss: 0.4437\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4131 - val_loss: 0.6272\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3982 - val_loss: 0.5036\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3930 - val_loss: 0.6336\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.4534\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3768 - val_loss: 0.6498\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3714 - val_loss: 0.4132\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3675 - val_loss: 0.5529\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3642 - val_loss: 0.4342\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3614 - val_loss: 0.6400\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3591 - val_loss: 0.4566\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3564 - val_loss: 0.5730\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3521 - val_loss: 0.4335\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3523 - val_loss: 0.6804\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3477 - val_loss: 0.5995\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3485 - val_loss: 0.7913\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3444 - val_loss: 0.6821\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3459 - val_loss: 1.0625\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3456 - val_loss: 0.8905\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3477 - val_loss: 1.1999\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3502 - val_loss: 0.9038\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3450 - val_loss: 1.0159\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3411 - val_loss: 1.0231\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3430 - val_loss: 0.8451\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3397 - val_loss: 0.6749\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3352 - val_loss: 0.6952\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3348 - val_loss: 0.5438\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3307 - val_loss: 0.5227\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3289 - val_loss: 0.3997\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3271 - val_loss: 0.3907\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3256 - val_loss: 0.3718\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3250 - val_loss: 0.3936\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3277 - val_loss: 0.3666\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3240 - val_loss: 0.4025\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3234 - val_loss: 0.4180\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3269 - val_loss: 0.4507\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3228 - val_loss: 0.4232\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3198 - val_loss: 0.4214\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3209 - val_loss: 0.4841\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3187 - val_loss: 0.4569\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3192 - val_loss: 0.5079\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3197 - val_loss: 0.6191\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3210 - val_loss: 0.5983\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3171 - val_loss: 0.6785\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3188 - val_loss: 0.6075\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3164 - val_loss: 0.7968\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3179 - val_loss: 0.9778\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3214 - val_loss: 1.2169\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3243 - val_loss: 1.7189\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3301 - val_loss: 1.5005\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3318 - val_loss: 1.2910\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3291 - val_loss: 0.8753\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3202 - val_loss: 0.6991\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3156 - val_loss: 0.4509\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3117 - val_loss: 0.4544\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3141 - val_loss: 0.3635\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3124 - val_loss: 0.3650\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3072 - val_loss: 0.3363\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3065 - val_loss: 0.3541\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3052 - val_loss: 0.3455\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3044 - val_loss: 0.3523\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3054 - val_loss: 0.3574\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3039 - val_loss: 0.3378\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3034 - val_loss: 0.3870\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3043 - val_loss: 0.3484\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3018 - val_loss: 0.4185\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3017 - val_loss: 0.4155\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3014 - val_loss: 0.5454\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3048 - val_loss: 0.4752\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3025 - val_loss: 0.7000\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3025 - val_loss: 0.6483\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3033 - val_loss: 0.9250\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3061 - val_loss: 0.9081\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3100 - val_loss: 0.9833\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3059 - val_loss: 0.8913\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3075 - val_loss: 0.9320\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3057 - val_loss: 1.2959\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3098 - val_loss: 1.3428\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3132 - val_loss: 0.9875\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3085 - val_loss: 0.8650\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3022 - val_loss: 0.6263\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3007 - val_loss: 0.5472\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2997 - val_loss: 0.4209\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2973 - val_loss: 0.4040\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2969 - val_loss: 0.3380\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2950 - val_loss: 0.3504\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2951 - val_loss: 0.3321\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2948 - val_loss: 0.3440\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2939 - val_loss: 0.3288\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2944 - val_loss: 0.3439\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2929 - val_loss: 0.3286\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2934 - val_loss: 0.3275\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2927 - val_loss: 0.3366\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2943 - val_loss: 0.3268\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2917 - val_loss: 0.3335\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2927 - val_loss: 0.3334\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2918 - val_loss: 0.3247\n",
      "121/121 [==============================] - 0s 726us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.7668 - val_loss: 0.9462\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9446 - val_loss: 1.3709\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5516 - val_loss: 1.3051\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9101 - val_loss: 1.7478\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5837 - val_loss: 2.5100\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6302 - val_loss: 4.0178\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6806 - val_loss: 3.0156\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5838 - val_loss: 2.9250\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2745 - val_loss: 1.7425\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7870 - val_loss: 0.8463\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5534 - val_loss: 0.6207\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5832 - val_loss: 4.3641\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5597 - val_loss: 2.4541\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6730 - val_loss: 11.3847\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.6966 - val_loss: 4.4622\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8407 - val_loss: 1.6503\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7692 - val_loss: 0.5451\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6953 - val_loss: 4.0844\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7049 - val_loss: 1.1713\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6981 - val_loss: 0.6744\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6268 - val_loss: 0.7199\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5355 - val_loss: 0.6070\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5990 - val_loss: 0.6042\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6925 - val_loss: 4.5958\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6838 - val_loss: 2.7469\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6377 - val_loss: 4.7071\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0652 - val_loss: 1.2902\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5964 - val_loss: 1.1966\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9471 - val_loss: 4.4003\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5920 - val_loss: 4.6826\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6995 - val_loss: 17.9808\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9689 - val_loss: 32.7104\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0131 - val_loss: 19.0103\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8428 - val_loss: 15.8084\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.7186 - val_loss: 8.1378\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.1459 - val_loss: 2.5625\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5857 - val_loss: 2.3482\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6244 - val_loss: 6.1946\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6948 - val_loss: 2.8907\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8882 - val_loss: 0.8422\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5670 - val_loss: 0.9208\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5391 - val_loss: 0.5452\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5448 - val_loss: 0.7121\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5284 - val_loss: 0.5358\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6237 - val_loss: 0.7034\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6708 - val_loss: 0.9678\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5639 - val_loss: 0.6525\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9872 - val_loss: 1.5369\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9987 - val_loss: 2.1632\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5627 - val_loss: 3.2732\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6016 - val_loss: 0.7531\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5336 - val_loss: 1.1912\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6872 - val_loss: 0.5683\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6120 - val_loss: 0.7394\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9069 - val_loss: 1.2956\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2454 - val_loss: 2.1983\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2987 - val_loss: 3.5816\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6372 - val_loss: 2.5701\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0832 - val_loss: 1.1909\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5673 - val_loss: 0.5381\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5930 - val_loss: 5.1702\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6967 - val_loss: 20.8941\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6.2736 - val_loss: 11.2986\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.2453 - val_loss: 4.6071\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5787 - val_loss: 4.2185\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1817 - val_loss: 1.1134\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6117 - val_loss: 0.6899\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6097 - val_loss: 0.7173\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6240 - val_loss: 0.7177\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5630 - val_loss: 1.1841\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5495 - val_loss: 2.2974\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5981 - val_loss: 4.7592\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3746 - val_loss: 1.5132\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6478 - val_loss: 1.8717\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6178 - val_loss: 13.3621\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8513 - val_loss: 17.8152\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9182 - val_loss: 38.8514\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 13.4273 - val_loss: 17.6194\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.5786 - val_loss: 7.0185\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6531 - val_loss: 8.8489\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.3847 - val_loss: 2.9611\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5755 - val_loss: 1.3417\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6863 - val_loss: 1.1299\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6054 - val_loss: 1.1218\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5561 - val_loss: 0.5381\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6252 - val_loss: 0.5321\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5635 - val_loss: 5.1263\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3851 - val_loss: 1.5494\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5798 - val_loss: 6.6292\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6584 - val_loss: 2.7815\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8575 - val_loss: 0.9104\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5383 - val_loss: 6.2370\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6848 - val_loss: 9.5583\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7235 - val_loss: 17.7206\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6.3642 - val_loss: 8.0421\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.7687 - val_loss: 5.0029\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3668 - val_loss: 1.5397\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7261 - val_loss: 0.5435\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5461 - val_loss: 0.9257\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5391 - val_loss: 0.7951\n",
      "121/121 [==============================] - 0s 776us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.9410 - val_loss: 85.4219\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 8.7376 - val_loss: 1106.4817\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 60.2877 - val_loss: 15455.9121\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 713.4445 - val_loss: 205104.3281\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 10196.7227 - val_loss: 2756550.0000\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 326924.6875 - val_loss: 37168920.0000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1736706.2500 - val_loss: 501303200.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 22461860.0000 - val_loss: 6743822336.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 741490112.0000 - val_loss: 90381721600.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 7601017344.0000 - val_loss: 1213723443200.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 118046801920.0000 - val_loss: 16315876114432.0000\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1784639782912.0000 - val_loss: 219315374653440.0000\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 16569943982080.0000 - val_loss: 2950105124569088.0000\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 159617812267008.0000 - val_loss: 39605671552876544.0000\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3017938495864832.0000 - val_loss: 532179536402448384.0000\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 42961256486797312.0000 - val_loss: 7156822890019553280.0000\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 831125512360296448.0000 - val_loss: 96069247934788534272.0000\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 7930758129694801920.0000 - val_loss: 1292031504646833963008.0000\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 103791593085682581504.0000 - val_loss: 17353169879092286193664.0000\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2027305505359990358016.0000 - val_loss: 233561594606227011141632.0000\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 22764941763420272721920.0000 - val_loss: 3135473506483358815748096.0000\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 220510000756520728395776.0000 - val_loss: 42043671518846220366774272.0000\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2883341102640887450566656.0000 - val_loss: 563956442365618731341578240.0000\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 64451120624307968237633536.0000 - val_loss: 7631775152258908520458485760.0000\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 644262202868200713993846784.0000 - val_loss: 102555642353213050845126459392.0000\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4732452867381244417166802944.0000 - val_loss: 1383258514084974419358739595264.0000\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 141397267235276300295713325056.0000 - val_loss: 18511248653108865658960474013696.0000\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1976971353272820820433046601728.0000 - val_loss: 248265373829509410164929414037504.0000\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 16683073551987215367465378775040.0000 - val_loss: 3334230563610064671005054211194880.0000\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 193872783726201485480478489182208.0000 - val_loss: 44775325627721561946486901865185280.0000\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3356065350022980208293724964257792.0000 - val_loss: inf\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 30398929881094155153239388391997440.0000 - val_loss: inf\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf        \n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf          \n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf          \n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: inf - val_loss: inf\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: inf - val_loss: inf\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: inf - val_loss: inf\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: inf - val_loss: inf\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: inf - val_loss: inf\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 779us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tmoia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tmoia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tmoia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tmoia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scikeras\\wrappers.py\", line 1117, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tmoia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scikeras\\wrappers.py\", line 1714, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tmoia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tmoia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py\", line 989, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tmoia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py\", line 101, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tmoia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\tmoia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"C:\\Users\\tmoia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1724 - val_loss: 0.6023\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5439 - val_loss: 0.5986\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5265 - val_loss: 0.5508\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5159 - val_loss: 0.5417\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5100 - val_loss: 0.6559\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5105 - val_loss: 0.5360\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5059 - val_loss: 0.6846\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5097 - val_loss: 0.5705\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5077 - val_loss: 0.5841\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5054 - val_loss: 0.7583\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5107 - val_loss: 0.5674\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5055 - val_loss: 0.6192\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5066 - val_loss: 0.6878\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5090 - val_loss: 0.5336\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5043 - val_loss: 0.7347\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5083 - val_loss: 0.6609\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5066 - val_loss: 0.6796\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5084 - val_loss: 0.5953\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5036 - val_loss: 0.8095\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5097 - val_loss: 0.6678\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5088 - val_loss: 0.5574\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5060 - val_loss: 0.5456\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5035 - val_loss: 0.7840\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5074 - val_loss: 0.7722\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5105 - val_loss: 0.5329\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5047 - val_loss: 0.7070\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5103 - val_loss: 0.5336\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5044 - val_loss: 0.6925\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5090 - val_loss: 0.5751\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5071 - val_loss: 0.5832\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5058 - val_loss: 0.6570\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5084 - val_loss: 0.5599\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5068 - val_loss: 0.5422\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5030 - val_loss: 0.8929\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5094 - val_loss: 0.7698\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5105 - val_loss: 0.5521\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5079 - val_loss: 0.5324\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5061 - val_loss: 0.5648\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5084 - val_loss: 0.5584\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5029 - val_loss: 0.8554\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5090 - val_loss: 0.7367\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5109 - val_loss: 0.5314\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5041 - val_loss: 0.7710\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5067 - val_loss: 0.7765\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5102 - val_loss: 0.5335\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5079 - val_loss: 0.5300\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5045 - val_loss: 0.6599\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5100 - val_loss: 0.5410\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5064 - val_loss: 0.5472\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5072 - val_loss: 0.5410\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5062 - val_loss: 0.5395\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5027 - val_loss: 0.9027\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5130 - val_loss: 0.5887\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5057 - val_loss: 0.6806\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5088 - val_loss: 0.5420\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5083 - val_loss: 0.5524\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5044 - val_loss: 0.7272\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5064 - val_loss: 0.7970\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5101 - val_loss: 0.5525\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5076 - val_loss: 0.5298\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5070 - val_loss: 0.5308\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5075 - val_loss: 0.5339\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5046 - val_loss: 0.6841\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5087 - val_loss: 0.5823\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5074 - val_loss: 0.5334\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5046 - val_loss: 0.6864\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5090 - val_loss: 0.5301\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5039 - val_loss: 0.7184\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5105 - val_loss: 0.5294\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5049 - val_loss: 0.6670\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5052 - val_loss: 0.7853\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5110 - val_loss: 0.5358\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5077 - val_loss: 0.5447\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5075 - val_loss: 0.5316\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5075 - val_loss: 0.5309\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5046 - val_loss: 0.7110\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5073 - val_loss: 0.7376\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5077 - val_loss: 0.7208\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5101 - val_loss: 0.5524\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5058 - val_loss: 0.6126\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5085 - val_loss: 0.5590\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5051 - val_loss: 0.6803\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5090 - val_loss: 0.5490\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5063 - val_loss: 0.6201\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5088 - val_loss: 0.5409\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5063 - val_loss: 0.5745\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5035 - val_loss: 0.8142\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5105 - val_loss: 0.5445\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5041 - val_loss: 0.8215\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5121 - val_loss: 0.5496\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5073 - val_loss: 0.5534\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5060 - val_loss: 0.6484\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5081 - val_loss: 0.6317\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5055 - val_loss: 0.7429\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5107 - val_loss: 0.5353\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5058 - val_loss: 0.5969\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5084 - val_loss: 0.5434\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5078 - val_loss: 0.5429\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5037 - val_loss: 0.8171\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5088 - val_loss: 0.6805\n",
      "121/121 [==============================] - 0s 751us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9635 - val_loss: 49.4098\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.1783 - val_loss: 0.5981\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4751 - val_loss: 0.4580\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4863 - val_loss: 0.4171\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7898 - val_loss: 0.4348\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4271 - val_loss: 0.4190\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3981 - val_loss: 0.4071\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3859 - val_loss: 0.4032\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3793 - val_loss: 0.3947\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3730 - val_loss: 0.3933\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3684 - val_loss: 0.3931\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3645 - val_loss: 0.3832\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3610 - val_loss: 0.3853\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3602 - val_loss: 0.3820\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3679 - val_loss: 0.3782\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3744 - val_loss: 0.3803\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3615 - val_loss: 0.3838\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3513 - val_loss: 0.3746\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3490 - val_loss: 0.3730\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3467 - val_loss: 0.3736\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3445 - val_loss: 0.3689\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3427 - val_loss: 0.3622\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3436 - val_loss: 0.3763\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3386 - val_loss: 0.3639\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3381 - val_loss: 0.3695\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3361 - val_loss: 0.3606\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3364 - val_loss: 0.3573\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3321 - val_loss: 0.3727\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3327 - val_loss: 0.3542\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3308 - val_loss: 0.3605\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3301 - val_loss: 0.3607\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3504 - val_loss: 0.3598\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3276 - val_loss: 0.3479\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3253 - val_loss: 0.3584\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3259 - val_loss: 0.3543\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3230 - val_loss: 0.3682\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3224 - val_loss: 0.3418\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3209 - val_loss: 0.3534\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3197 - val_loss: 0.3427\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3219 - val_loss: 0.3509\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3187 - val_loss: 0.3414\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3171 - val_loss: 0.3605\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3165 - val_loss: 0.3386\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3151 - val_loss: 0.3404\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3148 - val_loss: 0.3437\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3132 - val_loss: 0.3540\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3124 - val_loss: 0.3498\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3123 - val_loss: 0.3376\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3120 - val_loss: 0.3416\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3108 - val_loss: 0.3437\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3105 - val_loss: 0.3354\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3103 - val_loss: 0.3425\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3087 - val_loss: 0.3700\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3086 - val_loss: 0.3256\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3077 - val_loss: 0.3329\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3122 - val_loss: 0.5638\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3269 - val_loss: 0.3417\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3128 - val_loss: 0.3388\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3119 - val_loss: 0.3341\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3063 - val_loss: 0.3289\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3157 - val_loss: 0.3344\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3050 - val_loss: 0.3279\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3038 - val_loss: 0.3289\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3025 - val_loss: 0.3304\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3043 - val_loss: 0.3215\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3026 - val_loss: 0.3330\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3054 - val_loss: 0.3620\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3054 - val_loss: 0.3170\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3008 - val_loss: 0.3644\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3012 - val_loss: 0.3379\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3002 - val_loss: 0.3602\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3057 - val_loss: 0.3234\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2991 - val_loss: 0.3347\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2993 - val_loss: 0.3294\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2990 - val_loss: 0.4204\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2988 - val_loss: 0.3455\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2984 - val_loss: 0.3686\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2988 - val_loss: 0.3715\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3023 - val_loss: 0.3297\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2983 - val_loss: 0.3743\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2974 - val_loss: 0.3503\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2964 - val_loss: 0.3314\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2964 - val_loss: 0.3451\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2961 - val_loss: 0.3171\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2970 - val_loss: 0.3226\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2954 - val_loss: 0.3168\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2957 - val_loss: 0.3272\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2949 - val_loss: 0.3203\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2941 - val_loss: 0.3651\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2961 - val_loss: 0.3191\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2979 - val_loss: 0.3309\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2941 - val_loss: 0.3169\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2941 - val_loss: 0.4607\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3054 - val_loss: 0.3543\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2956 - val_loss: 0.4606\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2960 - val_loss: 0.3127\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2969 - val_loss: 0.3367\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2963 - val_loss: 0.3481\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2934 - val_loss: 0.3291\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2954 - val_loss: 0.3331\n",
      "121/121 [==============================] - 0s 790us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8678 - val_loss: 8.6988\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4158 - val_loss: 14.3717\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9961 - val_loss: 602.3187\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 776us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tmoia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tmoia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tmoia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tmoia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scikeras\\wrappers.py\", line 1117, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tmoia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scikeras\\wrappers.py\", line 1714, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tmoia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tmoia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py\", line 989, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tmoia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py\", line 101, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tmoia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\tmoia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"C:\\Users\\tmoia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8178 - val_loss: 1.4617\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5157 - val_loss: 1.8552\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4516 - val_loss: 1.0420\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4332 - val_loss: 0.8020\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4076 - val_loss: 0.4284\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3948 - val_loss: 0.4622\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3846 - val_loss: 0.4059\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3770 - val_loss: 0.4212\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3706 - val_loss: 0.3938\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3661 - val_loss: 0.4136\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3623 - val_loss: 0.3861\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3590 - val_loss: 0.3843\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3556 - val_loss: 0.3771\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3525 - val_loss: 0.3798\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3505 - val_loss: 0.4009\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3476 - val_loss: 0.3719\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3454 - val_loss: 0.3716\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3433 - val_loss: 0.3669\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3411 - val_loss: 0.3716\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3391 - val_loss: 0.3753\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3377 - val_loss: 0.3866\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3364 - val_loss: 0.3609\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3340 - val_loss: 0.3694\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3327 - val_loss: 0.3826\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3321 - val_loss: 0.3882\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3299 - val_loss: 0.4012\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3286 - val_loss: 0.3942\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3266 - val_loss: 0.4253\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3268 - val_loss: 0.5045\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3287 - val_loss: 0.6522\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3293 - val_loss: 0.8115\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3309 - val_loss: 0.8725\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3273 - val_loss: 0.9676\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3274 - val_loss: 0.9611\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3274 - val_loss: 1.2703\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3276 - val_loss: 1.1279\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3298 - val_loss: 1.8166\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3332 - val_loss: 1.4249\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3298 - val_loss: 0.9642\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3279 - val_loss: 0.5981\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3203 - val_loss: 0.4703\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3174 - val_loss: 0.3932\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3160 - val_loss: 0.4040\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3145 - val_loss: 0.3566\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3167 - val_loss: 0.3524\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3129 - val_loss: 0.3414\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3112 - val_loss: 0.3435\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3110 - val_loss: 0.3395\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3113 - val_loss: 0.3578\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3102 - val_loss: 0.3412\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3105 - val_loss: 0.3471\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3072 - val_loss: 0.3401\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3082 - val_loss: 0.3473\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3062 - val_loss: 0.3373\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3064 - val_loss: 0.3521\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3068 - val_loss: 0.3461\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3037 - val_loss: 0.3412\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3056 - val_loss: 0.3459\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3040 - val_loss: 0.3452\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3045 - val_loss: 0.3390\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3045 - val_loss: 0.3332\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3038 - val_loss: 0.3641\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3016 - val_loss: 0.3380\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3008 - val_loss: 0.3649\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2991 - val_loss: 0.3410\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2988 - val_loss: 0.4206\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3001 - val_loss: 0.3476\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3013 - val_loss: 0.4162\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2994 - val_loss: 0.3866\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2989 - val_loss: 0.5646\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2984 - val_loss: 0.6489\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3024 - val_loss: 0.9242\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3054 - val_loss: 0.9603\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3100 - val_loss: 1.4213\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3062 - val_loss: 1.5148\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3084 - val_loss: 1.4030\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3098 - val_loss: 1.1230\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3056 - val_loss: 1.9660\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3166 - val_loss: 1.8815\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3142 - val_loss: 1.0709\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3028 - val_loss: 0.4484\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2937 - val_loss: 0.3751\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2935 - val_loss: 0.3583\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2926 - val_loss: 0.3347\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2910 - val_loss: 0.3327\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2902 - val_loss: 0.3291\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2905 - val_loss: 0.3290\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2906 - val_loss: 0.3257\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2898 - val_loss: 0.3328\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2887 - val_loss: 0.3244\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2883 - val_loss: 0.3290\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2884 - val_loss: 0.3356\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2877 - val_loss: 0.3378\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2868 - val_loss: 0.3392\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2866 - val_loss: 0.3257\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2878 - val_loss: 0.3214\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2857 - val_loss: 0.3260\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2890 - val_loss: 0.3345\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2863 - val_loss: 0.3251\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2855 - val_loss: 0.3280\n",
      "121/121 [==============================] - 0s 821us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8325 - val_loss: 1.0931\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5180 - val_loss: 0.5079\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4613 - val_loss: 0.5374\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4312 - val_loss: 0.4333\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4110 - val_loss: 0.4533\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4009 - val_loss: 0.4433\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3936 - val_loss: 0.4120\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3908 - val_loss: 0.4004\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3833 - val_loss: 0.3929\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3804 - val_loss: 0.4566\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3790 - val_loss: 0.3769\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3744 - val_loss: 0.4265\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3730 - val_loss: 0.3859\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3678 - val_loss: 0.3854\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3679 - val_loss: 0.3882\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3622 - val_loss: 0.3800\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3642 - val_loss: 0.3912\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4856 - val_loss: 0.5271\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3675 - val_loss: 0.3860\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3578 - val_loss: 0.3896\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3533 - val_loss: 0.3626\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3518 - val_loss: 0.4233\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3520 - val_loss: 0.3534\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3492 - val_loss: 0.3768\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3478 - val_loss: 0.3572\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3472 - val_loss: 0.4137\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3449 - val_loss: 0.3539\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3429 - val_loss: 0.3808\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3417 - val_loss: 0.3542\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3378 - val_loss: 0.4219\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3382 - val_loss: 0.3492\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3364 - val_loss: 0.4043\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3375 - val_loss: 0.3412\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3359 - val_loss: 0.3703\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3321 - val_loss: 0.3383\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3309 - val_loss: 0.4237\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3288 - val_loss: 0.3439\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3276 - val_loss: 0.4041\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3288 - val_loss: 0.3356\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3241 - val_loss: 0.3540\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3245 - val_loss: 0.3504\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3252 - val_loss: 0.3327\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3206 - val_loss: 0.3499\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3199 - val_loss: 0.3370\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3205 - val_loss: 0.3655\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3185 - val_loss: 0.3452\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3166 - val_loss: 0.4773\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3267 - val_loss: 0.3598\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3217 - val_loss: 0.3535\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3155 - val_loss: 0.3400\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3143 - val_loss: 0.3508\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3125 - val_loss: 0.3418\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3123 - val_loss: 0.3402\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3095 - val_loss: 0.3315\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3086 - val_loss: 0.3405\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3078 - val_loss: 0.3409\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3064 - val_loss: 0.3667\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3072 - val_loss: 0.3208\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3064 - val_loss: 0.3437\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3053 - val_loss: 0.3290\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3021 - val_loss: 0.3863\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3035 - val_loss: 0.3303\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3036 - val_loss: 0.3376\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3023 - val_loss: 0.3535\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3018 - val_loss: 0.3293\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3021 - val_loss: 0.3379\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3007 - val_loss: 0.3508\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2999 - val_loss: 0.3230\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2993 - val_loss: 0.3432\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2987 - val_loss: 0.3283\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2970 - val_loss: 0.3327\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2961 - val_loss: 0.3244\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2990 - val_loss: 0.3202\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2960 - val_loss: 0.3953\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3004 - val_loss: 0.3104\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2996 - val_loss: 0.3605\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2990 - val_loss: 0.3127\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2975 - val_loss: 0.3600\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2952 - val_loss: 0.3236\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2943 - val_loss: 0.3197\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2933 - val_loss: 0.3526\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2945 - val_loss: 0.3308\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2938 - val_loss: 0.3249\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2937 - val_loss: 0.3193\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2926 - val_loss: 0.3438\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2953 - val_loss: 0.3259\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2927 - val_loss: 0.3339\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2916 - val_loss: 0.3522\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2901 - val_loss: 0.3294\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2913 - val_loss: 0.3326\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2899 - val_loss: 0.3166\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2902 - val_loss: 0.3318\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2897 - val_loss: 0.3303\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2896 - val_loss: 0.3358\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2892 - val_loss: 0.3286\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2876 - val_loss: 0.3354\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2873 - val_loss: 0.3333\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2892 - val_loss: 0.3406\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2889 - val_loss: 0.3180\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2878 - val_loss: 0.3376\n",
      "121/121 [==============================] - 0s 800us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0634 - val_loss: 6.7976\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9143 - val_loss: 0.9351\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5180 - val_loss: 0.4446\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4336 - val_loss: 0.4150\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4097 - val_loss: 0.3980\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3951 - val_loss: 0.3851\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3736\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3731 - val_loss: 0.3860\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3706 - val_loss: 0.3703\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3640 - val_loss: 0.3660\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3580 - val_loss: 0.3616\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3569 - val_loss: 0.3559\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3517 - val_loss: 0.3654\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3523 - val_loss: 0.3573\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3502 - val_loss: 0.3842\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3476 - val_loss: 0.3574\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3530 - val_loss: 0.3700\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3537 - val_loss: 0.3546\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3445 - val_loss: 0.3530\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3404 - val_loss: 0.3526\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3389 - val_loss: 0.3492\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3351 - val_loss: 0.3509\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3333 - val_loss: 0.3443\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3311 - val_loss: 0.3468\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3299 - val_loss: 0.3478\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3276 - val_loss: 0.3497\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3266 - val_loss: 0.3467\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3249 - val_loss: 0.3356\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3222 - val_loss: 0.3388\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3232 - val_loss: 0.3374\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3199 - val_loss: 0.3375\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3177 - val_loss: 0.3296\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3147 - val_loss: 0.3353\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3147 - val_loss: 0.3324\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3167 - val_loss: 0.3264\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3143 - val_loss: 0.3270\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3098 - val_loss: 0.3244\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3084 - val_loss: 0.3268\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3068 - val_loss: 0.3272\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3062 - val_loss: 0.3230\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3055 - val_loss: 0.3372\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3066 - val_loss: 0.3306\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3039 - val_loss: 0.3264\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3048 - val_loss: 0.3137\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3033 - val_loss: 0.3354\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3002 - val_loss: 0.3125\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2987 - val_loss: 0.3135\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2994 - val_loss: 0.3258\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2989 - val_loss: 0.3214\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2992 - val_loss: 0.3136\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2982 - val_loss: 0.3169\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2953 - val_loss: 0.3199\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2961 - val_loss: 0.3128\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2958 - val_loss: 0.3483\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2952 - val_loss: 0.3132\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2945 - val_loss: 0.3226\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2951 - val_loss: 0.3082\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2934 - val_loss: 0.3126\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2935 - val_loss: 0.4111\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2991 - val_loss: 0.3466\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3589 - val_loss: 0.3402\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3299 - val_loss: 0.3272\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3130 - val_loss: 0.3243\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3030 - val_loss: 0.3138\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3429 - val_loss: 0.3216\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3018 - val_loss: 0.3306\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3090 - val_loss: 0.3269\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2952 - val_loss: 0.3195\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2925 - val_loss: 0.3136\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2913 - val_loss: 0.3174\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2900 - val_loss: 0.3130\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2897 - val_loss: 0.3092\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2902 - val_loss: 0.3111\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2918 - val_loss: 0.3435\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2939 - val_loss: 0.3286\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2895 - val_loss: 0.3137\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2896 - val_loss: 0.3184\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2871 - val_loss: 0.3105\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2885 - val_loss: 0.3123\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2869 - val_loss: 0.3582\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2848 - val_loss: 0.3201\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2879 - val_loss: 0.3233\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2898 - val_loss: 0.3144\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2898 - val_loss: 0.3299\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3485 - val_loss: 0.3011\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3082 - val_loss: 0.3368\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3021 - val_loss: 0.3166\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2926 - val_loss: 0.3190\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3042 - val_loss: 0.3369\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2975 - val_loss: 0.3317\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2900 - val_loss: 0.3377\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2881 - val_loss: 0.3116\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2881 - val_loss: 0.3106\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2834 - val_loss: 0.3089\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2818 - val_loss: 0.3156\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2823 - val_loss: 0.3232\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2821 - val_loss: 0.3045\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2808 - val_loss: 0.3030\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2818 - val_loss: 0.3166\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2800 - val_loss: 0.3052\n",
      "121/121 [==============================] - 0s 831us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8998 - val_loss: 0.6346\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5544 - val_loss: 0.5982\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4822 - val_loss: 0.4899\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4395 - val_loss: 0.4442\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4164 - val_loss: 0.5294\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3944 - val_loss: 0.4161\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.3939\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3733 - val_loss: 0.3931\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3656 - val_loss: 0.4242\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3592 - val_loss: 0.3951\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3575 - val_loss: 0.3837\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3527 - val_loss: 0.3824\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3464 - val_loss: 0.3804\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3510 - val_loss: 0.3946\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3392 - val_loss: 0.3821\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3361 - val_loss: 0.3692\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3321 - val_loss: 0.3737\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3301 - val_loss: 0.3654\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3287 - val_loss: 0.3748\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3256 - val_loss: 0.3642\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3238 - val_loss: 0.3697\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3235 - val_loss: 0.3589\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3198 - val_loss: 0.3643\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3195 - val_loss: 0.3617\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3158 - val_loss: 0.3503\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3179 - val_loss: 0.3435\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3149 - val_loss: 0.3545\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3130 - val_loss: 0.3471\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3145 - val_loss: 0.3519\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3114 - val_loss: 0.3509\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3093 - val_loss: 0.3376\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3069 - val_loss: 0.3517\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3060 - val_loss: 0.3420\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3048 - val_loss: 0.3346\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3064 - val_loss: 0.3495\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3056 - val_loss: 0.3345\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3028 - val_loss: 0.3545\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2993 - val_loss: 0.3424\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3008 - val_loss: 0.3315\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3024 - val_loss: 0.3284\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2967 - val_loss: 0.3358\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2970 - val_loss: 0.3295\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2956 - val_loss: 0.3241\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2947 - val_loss: 0.3555\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2972 - val_loss: 0.3355\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2931 - val_loss: 0.3248\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2910 - val_loss: 0.3456\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2888 - val_loss: 0.3237\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2887 - val_loss: 0.3266\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2907 - val_loss: 0.3470\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2879 - val_loss: 0.3318\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2865 - val_loss: 0.3350\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2862 - val_loss: 0.3225\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2861 - val_loss: 0.3475\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2842 - val_loss: 0.3183\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2847 - val_loss: 0.3444\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2833 - val_loss: 0.3421\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2845 - val_loss: 0.3622\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2843 - val_loss: 0.3208\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2809 - val_loss: 0.3125\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2812 - val_loss: 0.3261\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2817 - val_loss: 0.3172\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2810 - val_loss: 0.3157\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2790 - val_loss: 0.3222\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2797 - val_loss: 0.3199\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2784 - val_loss: 0.3171\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2782 - val_loss: 0.3374\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2772 - val_loss: 0.3283\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2795 - val_loss: 0.3260\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2782 - val_loss: 0.3129\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2765 - val_loss: 0.3064\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2767 - val_loss: 0.3098\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2755 - val_loss: 0.3101\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2739 - val_loss: 0.3172\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2755 - val_loss: 0.3150\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2736 - val_loss: 0.3874\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2742 - val_loss: 0.3473\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2727 - val_loss: 0.3702\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2743 - val_loss: 0.3340\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2731 - val_loss: 0.3993\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2731 - val_loss: 0.3593\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2723 - val_loss: 0.4795\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2729 - val_loss: 0.3620\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2727 - val_loss: 0.4767\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2729 - val_loss: 0.3989\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2730 - val_loss: 0.5895\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2741 - val_loss: 0.4547\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2765 - val_loss: 0.6304\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2730 - val_loss: 0.4011\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2720 - val_loss: 0.4101\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2695 - val_loss: 0.3396\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2691 - val_loss: 0.3871\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2682 - val_loss: 0.3183\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2679 - val_loss: 0.3930\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2674 - val_loss: 0.3127\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2668 - val_loss: 0.3296\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2659 - val_loss: 0.3053\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2669 - val_loss: 0.3803\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2657 - val_loss: 0.3200\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2660 - val_loss: 0.4150\n",
      "121/121 [==============================] - 0s 795us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.7941 - val_loss: 1.2959\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2979 - val_loss: 1.2396\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1782 - val_loss: 1.0516\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9187 - val_loss: 0.8113\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7449 - val_loss: 0.7072\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6518 - val_loss: 0.6249\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5846 - val_loss: 0.5781\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.6418\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5985 - val_loss: 0.5968\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5660 - val_loss: 0.5651\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5383 - val_loss: 0.5378\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5580 - val_loss: 0.5967\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5673 - val_loss: 0.5652\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5439 - val_loss: 0.5463\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5188 - val_loss: 0.5486\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5648 - val_loss: 0.5640\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5368 - val_loss: 0.5372\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5153 - val_loss: 0.5152\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5261 - val_loss: 0.5265\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5073 - val_loss: 0.5261\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5048 - val_loss: 0.6092\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5141 - val_loss: 0.5499\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5252 - val_loss: 0.5268\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5070 - val_loss: 0.6348\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5089 - val_loss: 0.5239\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5319 - val_loss: 0.5329\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5085 - val_loss: 0.5446\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5932 - val_loss: 0.6537\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6125 - val_loss: 0.6084\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5790 - val_loss: 0.5812\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5523 - val_loss: 0.5613\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5313 - val_loss: 0.5393\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5165 - val_loss: 0.5260\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5067 - val_loss: 0.5264\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5039 - val_loss: 0.5124\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5134 - val_loss: 0.5414\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5184 - val_loss: 0.5264\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5044 - val_loss: 0.5588\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5537 - val_loss: 0.5544\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5316 - val_loss: 0.5380\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5155 - val_loss: 0.5212\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5144 - val_loss: 0.5578\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5294 - val_loss: 0.5339\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5127 - val_loss: 0.5190\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5185 - val_loss: 0.5369\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5187 - val_loss: 0.5254\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5098 - val_loss: 0.5290\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5044 - val_loss: 0.5378\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5276 - val_loss: 0.5696\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5408 - val_loss: 0.5468\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5234 - val_loss: 0.5294\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5106 - val_loss: 0.5158\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5212 - val_loss: 0.5446\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5251 - val_loss: 0.5294\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5112 - val_loss: 0.5105\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5302 - val_loss: 0.5531\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5308 - val_loss: 0.5419\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5176 - val_loss: 0.5254\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5075 - val_loss: 0.5217\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5208 - val_loss: 0.5584\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5336 - val_loss: 0.5417\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5185 - val_loss: 0.5269\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5092 - val_loss: 0.5138\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5308 - val_loss: 0.5664\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5395 - val_loss: 0.5469\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5264 - val_loss: 0.5338\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5132 - val_loss: 0.5229\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5069 - val_loss: 0.5234\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5046 - val_loss: 0.5164\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5128 - val_loss: 0.5212\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5067 - val_loss: 0.5400\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5107 - val_loss: 0.5218\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5170 - val_loss: 0.5321\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5124 - val_loss: 0.5330\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5026 - val_loss: 0.5468\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5399 - val_loss: 0.5473\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5260 - val_loss: 0.5399\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5147 - val_loss: 0.5280\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5048 - val_loss: 0.5203\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5176 - val_loss: 0.5339\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5152 - val_loss: 0.5306\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5069 - val_loss: 0.5242\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5062 - val_loss: 0.5161\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5095 - val_loss: 0.5220\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5057 - val_loss: 0.5207\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5145 - val_loss: 0.5395\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5233 - val_loss: 0.5291\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5106 - val_loss: 0.5253\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5056 - val_loss: 0.5227\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5002 - val_loss: 0.6579\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5453 - val_loss: 0.5399\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5175 - val_loss: 0.5264\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5085 - val_loss: 0.5150\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5161 - val_loss: 0.5380\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5155 - val_loss: 0.5255\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5063 - val_loss: 0.5115\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5180 - val_loss: 0.5448\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5207 - val_loss: 0.5280\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5102 - val_loss: 0.5222\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5112 - val_loss: 0.5293\n",
      "121/121 [==============================] - 0s 758us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.9023 - val_loss: 1.3146\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4104 - val_loss: 1.3405\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3580 - val_loss: 1.4925\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4206 - val_loss: 1.9128\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4387 - val_loss: 1.3116\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3558 - val_loss: 1.2763\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2422 - val_loss: 1.0763\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9868 - val_loss: 0.8784\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8361 - val_loss: 0.7715\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7124 - val_loss: 0.7697\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7104 - val_loss: 0.7935\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7431 - val_loss: 0.6987\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6811 - val_loss: 0.6478\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6338 - val_loss: 0.6111\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5971 - val_loss: 0.5772\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5686 - val_loss: 0.5534\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5467 - val_loss: 0.5318\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5474 - val_loss: 0.5447\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5378 - val_loss: 0.5266\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5413 - val_loss: 0.5544\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5404 - val_loss: 0.5293\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5280 - val_loss: 0.5312\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5266 - val_loss: 0.5202\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5517 - val_loss: 0.5519\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5505 - val_loss: 0.5313\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5197 - val_loss: 0.5705\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5746 - val_loss: 0.5584\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5477 - val_loss: 0.5358\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5228 - val_loss: 0.5151\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5647 - val_loss: 0.5995\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5821 - val_loss: 0.5655\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5572 - val_loss: 0.5435\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5349 - val_loss: 0.5289\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5286 - val_loss: 0.5275\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5217 - val_loss: 0.5345\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5265 - val_loss: 0.5207\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5397 - val_loss: 0.5746\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5607 - val_loss: 0.5494\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5385 - val_loss: 0.5323\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5234 - val_loss: 0.5182\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5382 - val_loss: 0.5388\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5264 - val_loss: 0.5233\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5194 - val_loss: 0.5243\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5281 - val_loss: 0.5321\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5210 - val_loss: 0.5144\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5442 - val_loss: 0.5524\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5419 - val_loss: 0.5345\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5279 - val_loss: 0.5340\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5276 - val_loss: 0.5624\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5431 - val_loss: 0.5351\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5265 - val_loss: 0.5206\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5167 - val_loss: 0.5673\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5454 - val_loss: 0.5319\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5250 - val_loss: 0.5262\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5313 - val_loss: 0.5500\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5392 - val_loss: 0.5282\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5233 - val_loss: 0.5232\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5251 - val_loss: 0.5331\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5191 - val_loss: 0.5348\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5233 - val_loss: 0.5199\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5250 - val_loss: 0.5297\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5202 - val_loss: 0.5140\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5129 - val_loss: 0.6533\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5835 - val_loss: 0.5718\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5601 - val_loss: 0.5601\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5412 - val_loss: 0.5362\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5272 - val_loss: 0.5243\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5158 - val_loss: 0.5169\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5311 - val_loss: 0.5493\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5364 - val_loss: 0.5325\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5232 - val_loss: 0.5199\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5150 - val_loss: 0.5127\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5370 - val_loss: 0.5629\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5504 - val_loss: 0.5409\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5355 - val_loss: 0.5417\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5245 - val_loss: 0.5243\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5131 - val_loss: 0.5567\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5576 - val_loss: 0.5540\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5402 - val_loss: 0.5333\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5264 - val_loss: 0.5267\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5176 - val_loss: 0.5195\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5298 - val_loss: 0.5262\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5178 - val_loss: 0.5153\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5298 - val_loss: 0.5476\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5311 - val_loss: 0.5332\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5196 - val_loss: 0.5219\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5214 - val_loss: 0.5316\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5223 - val_loss: 0.5222\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5164 - val_loss: 0.5236\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5131 - val_loss: 0.6433\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5685 - val_loss: 0.5516\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5405 - val_loss: 0.5365\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5280 - val_loss: 0.5280\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5176 - val_loss: 0.5120\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5246 - val_loss: 0.5280\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5239 - val_loss: 0.5262\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5149 - val_loss: 0.5314\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5250 - val_loss: 0.5269\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5141 - val_loss: 0.5442\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5388 - val_loss: 0.5345\n",
      "121/121 [==============================] - 0s 758us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.0326 - val_loss: 1.3051\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2925 - val_loss: 1.2910\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2604 - val_loss: 1.2589\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1975 - val_loss: 1.1513\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9603 - val_loss: 0.8779\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7597 - val_loss: 0.8604\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6380 - val_loss: 0.8015\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5850 - val_loss: 0.5860\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5416 - val_loss: 0.9356\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5393 - val_loss: 0.5719\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5339 - val_loss: 0.5646\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5263 - val_loss: 0.5306\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5183 - val_loss: 0.5587\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5158 - val_loss: 0.5472\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5099 - val_loss: 0.5208\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5122 - val_loss: 0.5414\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5040 - val_loss: 0.7864\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5177 - val_loss: 0.5346\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4951 - val_loss: 1.1283\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5226 - val_loss: 0.5241\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5011 - val_loss: 0.5397\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4958 - val_loss: 0.8869\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5185 - val_loss: 0.5445\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5085 - val_loss: 0.5108\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5015 - val_loss: 0.5258\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4914 - val_loss: 1.1234\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5165 - val_loss: 0.5326\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4977 - val_loss: 0.5126\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5028 - val_loss: 0.5286\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4942 - val_loss: 0.7231\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5054 - val_loss: 0.5115\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4984 - val_loss: 0.5379\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4995 - val_loss: 0.5854\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5015 - val_loss: 0.5211\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4955 - val_loss: 0.5264\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4913 - val_loss: 0.8831\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5032 - val_loss: 0.5221\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4993 - val_loss: 0.5201\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4955 - val_loss: 0.5389\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4971 - val_loss: 0.5103\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4973 - val_loss: 0.5326\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4915 - val_loss: 0.8504\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5071 - val_loss: 0.5362\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5016 - val_loss: 0.5129\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4959 - val_loss: 0.5114\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4906 - val_loss: 0.6018\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5004 - val_loss: 0.5211\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4931 - val_loss: 0.5164\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4946 - val_loss: 0.5324\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4941 - val_loss: 0.5085\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4864 - val_loss: 1.1341\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5073 - val_loss: 0.5217\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4895 - val_loss: 1.0510\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5061 - val_loss: 0.5193\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4911 - val_loss: 0.6460\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4975 - val_loss: 0.5422\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4898 - val_loss: 1.0162\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5034 - val_loss: 0.5116\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4833 - val_loss: 1.2424\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5063 - val_loss: 0.5254\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4934 - val_loss: 0.6607\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4993 - val_loss: 0.5292\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4924 - val_loss: 0.5724\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4921 - val_loss: 0.6890\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4974 - val_loss: 0.5154\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4857 - val_loss: 1.1182\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5059 - val_loss: 0.5310\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4947 - val_loss: 0.5628\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4945 - val_loss: 0.5100\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4922 - val_loss: 0.5186\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4928 - val_loss: 0.5170\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4919 - val_loss: 0.5463\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4926 - val_loss: 0.5982\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4943 - val_loss: 0.5476\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4937 - val_loss: 0.5989\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4933 - val_loss: 0.6133\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4955 - val_loss: 0.5102\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4874 - val_loss: 0.9393\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4993 - val_loss: 0.5439\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4945 - val_loss: 0.5176\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4878 - val_loss: 0.8201\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4981 - val_loss: 0.5065\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4901 - val_loss: 0.6670\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4936 - val_loss: 0.5956\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4937 - val_loss: 0.5736\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4904 - val_loss: 0.7442\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4963 - val_loss: 0.5238\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4921 - val_loss: 0.5276\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4931 - val_loss: 0.5114\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4861 - val_loss: 1.0078\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5033 - val_loss: 0.5264\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4881 - val_loss: 0.8718\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4934 - val_loss: 0.6714\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4909 - val_loss: 0.7825\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4987 - val_loss: 0.5118\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4911 - val_loss: 0.5103\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4873 - val_loss: 0.6967\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4971 - val_loss: 0.5074\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4927 - val_loss: 0.5126\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4922 - val_loss: 0.5130\n",
      "121/121 [==============================] - 0s 731us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.4495 - val_loss: 8.0104\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6619 - val_loss: 3.1795\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7317 - val_loss: 1.9321\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5739 - val_loss: 0.6997\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5808 - val_loss: 2.5460\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9709 - val_loss: 0.9283\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5553 - val_loss: 0.7145\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6752 - val_loss: 1.5242\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8735 - val_loss: 0.7121\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5451 - val_loss: 0.6877\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8471 - val_loss: 1.3487\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5617 - val_loss: 4.6877\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6966 - val_loss: 4.5122\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6879 - val_loss: 12.1187\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.9580 - val_loss: 4.3860\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6542 - val_loss: 5.5688\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6472 - val_loss: 3.8044\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6076 - val_loss: 9.7776\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.6626 - val_loss: 4.6311\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7008 - val_loss: 16.5021\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.1093 - val_loss: 8.0326\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.6683 - val_loss: 3.3671\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6462 - val_loss: 13.8202\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7497 - val_loss: 11.8866\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9254 - val_loss: 12.9880\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8321 - val_loss: 8.6645\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8744 - val_loss: 3.2777\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9464 - val_loss: 0.9806\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6160 - val_loss: 0.5420\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5614 - val_loss: 0.6361\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8117 - val_loss: 0.8093\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5710 - val_loss: 0.5444\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6148 - val_loss: 2.5525\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6660 - val_loss: 1.7707\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9446 - val_loss: 1.0565\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6586 - val_loss: 0.5488\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5556 - val_loss: 1.5591\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7763 - val_loss: 0.5494\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6032 - val_loss: 0.6678\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5427 - val_loss: 0.7946\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6871 - val_loss: 0.7098\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5766 - val_loss: 0.6665\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5603 - val_loss: 3.1241\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7273 - val_loss: 1.6033\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6285 - val_loss: 5.4146\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1656 - val_loss: 1.9467\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5836 - val_loss: 7.8256\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7373 - val_loss: 19.0690\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8891 - val_loss: 19.9214\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8858 - val_loss: 10.3048\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.2321 - val_loss: 5.4720\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6744 - val_loss: 6.1096\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6982 - val_loss: 20.2788\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9009 - val_loss: 18.5049\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0031 - val_loss: 32.1945\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 7.7805 - val_loss: 15.5197\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8350 - val_loss: 12.4073\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.1052 - val_loss: 4.7001\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5904 - val_loss: 3.1121\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2635 - val_loss: 1.0008\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6879 - val_loss: 0.6740\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3311 - val_loss: 2.0620\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6008 - val_loss: 3.3269\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1659 - val_loss: 1.4299\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6281 - val_loss: 0.6660\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5590 - val_loss: 1.2255\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5798 - val_loss: 5.1673\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6542 - val_loss: 11.3069\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7684 - val_loss: 8.1264\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6998 - val_loss: 12.7292\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7064 - val_loss: 11.6512\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7646 - val_loss: 14.8705\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8567 - val_loss: 19.8924\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6.2579 - val_loss: 9.0882\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8233 - val_loss: 13.7977\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.6858 - val_loss: 7.6244\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7564 - val_loss: 15.5035\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8657 - val_loss: 7.2339\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9379 - val_loss: 21.1712\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8325 - val_loss: 11.2206\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.7186 - val_loss: 8.2491\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7468 - val_loss: 10.7730\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7175 - val_loss: 9.7537\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6946 - val_loss: 21.7802\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 7.0672 - val_loss: 13.4671\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 4.6525 - val_loss: 5.2009\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7079 - val_loss: 25.4060\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0625 - val_loss: 40.0755\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 12.3404 - val_loss: 19.1308\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8970 - val_loss: 18.6433\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8482 - val_loss: 25.1558\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9900 - val_loss: 21.4878\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9412 - val_loss: 15.8927\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0984 - val_loss: 7.1189\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.5040 - val_loss: 3.9114\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7712 - val_loss: 0.7777\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6299 - val_loss: 0.7582\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5516 - val_loss: 0.6253\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6359 - val_loss: 2.2689\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6500 - val_loss: 0.6481\n",
      "121/121 [==============================] - 0s 775us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.5072 - val_loss: 78.7130\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.4820 - val_loss: 868.7761\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 56.1392 - val_loss: 11985.6836\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 816.5165 - val_loss: 159708.6406\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 18446.4082 - val_loss: 2146651.0000\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 111454.1641 - val_loss: 28878702.0000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2325251.7500 - val_loss: 387734368.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 36006096.0000 - val_loss: 5208195072.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 528842944.0000 - val_loss: 69858312192.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6548939776.0000 - val_loss: 939500437504.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 110108377088.0000 - val_loss: 12639788859392.0000\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 544441368576.0000 - val_loss: 171364346494976.0000\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 12969798795264.0000 - val_loss: 2290101526724608.0000\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 96287118589952.0000 - val_loss: 31072331744935936.0000\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2415847163297792.0000 - val_loss: 414564468341604352.0000\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 21156809184116736.0000 - val_loss: 5558610171279704064.0000\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 527951364437835776.0000 - val_loss: 74649362846921523200.0000\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 7875855665829249024.0000 - val_loss: 1002689935655812726784.0000\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 58225706974180278272.0000 - val_loss: 13481481574437212913664.0000\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 699872400311047946240.0000 - val_loss: 181566870375489783988224.0000\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 10326762952759802068992.0000 - val_loss: 2441469524481505761427456.0000\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 266613530285897590767616.0000 - val_loss: 32881840126064348836659200.0000\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1559218680935267870703616.0000 - val_loss: 443965979976336505783189504.0000\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 37343448046394054256099328.0000 - val_loss: 5935642192310807690349641728.0000\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 326148728506378002500681728.0000 - val_loss: 80001752257289145654580346880.0000\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 5371718437575687572333527040.0000 - val_loss: 1074316463072363770962048450560.0000\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 47378416778340090410612817920.0000 - val_loss: 14466443988655353200295345651712.0000\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1112405559965915810969252003840.0000 - val_loss: 193263833283751761389628891856896.0000\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 9817806264746545376077151207424.0000 - val_loss: 2599090084285765699143477208547328.0000\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 116628052611442806930191274737664.0000 - val_loss: 35080950331315627603217015514333184.0000\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 4157214649152034584483335619215360.0000 - val_loss: inf\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 28170892826028563446757594008387584.0000 - val_loss: inf\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: inf - val_loss: inf                 \n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: inf - val_loss: inf          \n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf           \n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf           \n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: inf - val_loss: inf\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 796us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tmoia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tmoia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tmoia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tmoia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scikeras\\wrappers.py\", line 1117, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tmoia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scikeras\\wrappers.py\", line 1714, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tmoia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tmoia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py\", line 989, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tmoia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py\", line 101, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tmoia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\tmoia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"C:\\Users\\tmoia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.2057 - val_loss: 0.7782\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5465 - val_loss: 0.6173\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5274 - val_loss: 0.5595\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5162 - val_loss: 0.6096\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5109 - val_loss: 0.6928\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5088 - val_loss: 0.8085\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5131 - val_loss: 0.5361\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5059 - val_loss: 0.6474\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5086 - val_loss: 0.5701\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5077 - val_loss: 0.5320\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5062 - val_loss: 0.5853\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5081 - val_loss: 0.5476\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5070 - val_loss: 0.5764\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5036 - val_loss: 0.8061\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5123 - val_loss: 0.5596\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5074 - val_loss: 0.5290\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5066 - val_loss: 0.5479\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5079 - val_loss: 0.5304\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5033 - val_loss: 0.8106\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5117 - val_loss: 0.5324\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5069 - val_loss: 0.5462\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5051 - val_loss: 0.6781\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5087 - val_loss: 0.5278\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5069 - val_loss: 0.5335\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5066 - val_loss: 0.5782\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5055 - val_loss: 0.7036\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5080 - val_loss: 0.6744\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5092 - val_loss: 0.5697\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5055 - val_loss: 0.6561\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5062 - val_loss: 0.7826\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5109 - val_loss: 0.5283\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5080 - val_loss: 0.5312\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5046 - val_loss: 0.6445\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5091 - val_loss: 0.5515\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5045 - val_loss: 0.6976\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5094 - val_loss: 0.6034\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5081 - val_loss: 0.5369\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5080 - val_loss: 0.5515\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5068 - val_loss: 0.5314\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5071 - val_loss: 0.5298\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5067 - val_loss: 0.5611\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5048 - val_loss: 0.6952\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5073 - val_loss: 0.6241\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5077 - val_loss: 0.5992\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5086 - val_loss: 0.5298\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5066 - val_loss: 0.5525\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5078 - val_loss: 0.5418\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5055 - val_loss: 0.6387\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5078 - val_loss: 0.6028\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5055 - val_loss: 0.7177\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5052 - val_loss: 0.8181\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5117 - val_loss: 0.5305\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5041 - val_loss: 0.7786\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5116 - val_loss: 0.5334\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5072 - val_loss: 0.5379\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5067 - val_loss: 0.5459\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5060 - val_loss: 0.6051\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5070 - val_loss: 0.6593\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5071 - val_loss: 0.6424\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5060 - val_loss: 0.7578\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5109 - val_loss: 0.5384\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5058 - val_loss: 0.6441\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5075 - val_loss: 0.6484\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5097 - val_loss: 0.5303\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5035 - val_loss: 0.6810\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5069 - val_loss: 0.7307\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5108 - val_loss: 0.5352\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5065 - val_loss: 0.5365\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5050 - val_loss: 0.6738\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5077 - val_loss: 0.6094\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5081 - val_loss: 0.5306\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5047 - val_loss: 0.7322\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5086 - val_loss: 0.6628\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5089 - val_loss: 0.5362\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5046 - val_loss: 0.7139\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5099 - val_loss: 0.5384\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5067 - val_loss: 0.5297\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5073 - val_loss: 0.5323\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5072 - val_loss: 0.5368\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5071 - val_loss: 0.5295\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5071 - val_loss: 0.5343\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5031 - val_loss: 0.8301\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5114 - val_loss: 0.5919\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5077 - val_loss: 0.5482\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5047 - val_loss: 0.7034\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5059 - val_loss: 0.8132\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5095 - val_loss: 0.6608\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5054 - val_loss: 0.7092\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5092 - val_loss: 0.5776\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5064 - val_loss: 0.6701\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5093 - val_loss: 0.5666\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5072 - val_loss: 0.5878\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5043 - val_loss: 0.7544\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5086 - val_loss: 0.6430\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5086 - val_loss: 0.5746\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5089 - val_loss: 0.5495\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5055 - val_loss: 0.6889\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5091 - val_loss: 0.5638\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5030 - val_loss: 0.8262\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5109 - val_loss: 0.5889\n",
      "121/121 [==============================] - 0s 790us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9998 - val_loss: 34.1795\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8852 - val_loss: 0.5159\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4682 - val_loss: 0.4585\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4341 - val_loss: 0.4365\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4352 - val_loss: 0.4314\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4111 - val_loss: 0.4170\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4029 - val_loss: 0.4171\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3977 - val_loss: 0.4231\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3920 - val_loss: 0.4077\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3890 - val_loss: 0.4091\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3857 - val_loss: 0.4055\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.4062\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3817 - val_loss: 0.4086\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3803 - val_loss: 0.4181\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3850 - val_loss: 0.4126\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3811 - val_loss: 0.4055\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3984 - val_loss: 0.4276\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3801 - val_loss: 0.4057\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3717 - val_loss: 0.4004\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3732 - val_loss: 0.4017\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3671 - val_loss: 0.3971\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3665 - val_loss: 0.3965\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3661 - val_loss: 0.4229\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3727 - val_loss: 0.3941\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3669 - val_loss: 0.3958\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3718 - val_loss: 0.4039\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3693 - val_loss: 0.3882\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3594 - val_loss: 0.3899\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3560 - val_loss: 0.4057\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3649 - val_loss: 0.3870\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3676 - val_loss: 0.3834\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3545 - val_loss: 0.3861\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3533 - val_loss: 0.3896\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3526 - val_loss: 0.3835\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3487 - val_loss: 0.3874\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3499 - val_loss: 0.3888\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3542 - val_loss: 0.3796\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3456 - val_loss: 0.3812\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3772 - val_loss: 0.3769\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3532 - val_loss: 0.3841\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3473 - val_loss: 0.4130\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3458 - val_loss: 0.3706\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3427 - val_loss: 0.3771\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3413 - val_loss: 0.3663\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3400 - val_loss: 0.3661\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3362 - val_loss: 0.3667\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3361 - val_loss: 0.3670\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3444 - val_loss: 0.3653\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3343 - val_loss: 0.3617\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3328 - val_loss: 0.3687\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3314 - val_loss: 0.3641\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3309 - val_loss: 0.3664\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3332 - val_loss: 0.4101\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3366 - val_loss: 0.3650\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3293 - val_loss: 0.3612\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3278 - val_loss: 0.3653\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3273 - val_loss: 0.3536\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3270 - val_loss: 0.3693\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3259 - val_loss: 0.3564\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3251 - val_loss: 0.3564\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3290 - val_loss: 0.3534\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3233 - val_loss: 0.3607\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3227 - val_loss: 0.3581\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3217 - val_loss: 0.3525\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3212 - val_loss: 0.3555\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3204 - val_loss: 0.3590\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3195 - val_loss: 0.3527\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3196 - val_loss: 0.3524\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3199 - val_loss: 0.3481\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3178 - val_loss: 0.3600\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3198 - val_loss: 0.3467\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3173 - val_loss: 0.3518\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3164 - val_loss: 0.3477\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3160 - val_loss: 0.3500\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3156 - val_loss: 0.3442\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3168 - val_loss: 0.3529\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3212 - val_loss: 0.3499\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3139 - val_loss: 0.3485\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3168 - val_loss: 0.3459\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3162 - val_loss: 0.3479\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3134 - val_loss: 0.3540\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3130 - val_loss: 0.3501\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3123 - val_loss: 0.3489\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3149 - val_loss: 0.4126\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3153 - val_loss: 0.3408\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3119 - val_loss: 0.3555\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3120 - val_loss: 0.3440\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3132 - val_loss: 0.3501\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3101 - val_loss: 0.3433\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3104 - val_loss: 0.3581\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3102 - val_loss: 0.3464\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3099 - val_loss: 0.3565\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3096 - val_loss: 0.3351\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3104 - val_loss: 0.3542\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3098 - val_loss: 0.3416\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3167 - val_loss: 0.3527\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3091 - val_loss: 0.3467\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3076 - val_loss: 0.3520\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3072 - val_loss: 0.3555\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3062 - val_loss: 0.3343\n",
      "121/121 [==============================] - 0s 881us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9559 - val_loss: 6.1072\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9420 - val_loss: 4.8805\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0285 - val_loss: 2.5750\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6175 - val_loss: 0.4824\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4634 - val_loss: 0.4240\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4407 - val_loss: 0.4127\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4134 - val_loss: 0.4006\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3966 - val_loss: 0.3893\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3895 - val_loss: 0.3882\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3820 - val_loss: 0.3803\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3807 - val_loss: 0.3830\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3774 - val_loss: 0.3740\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3696 - val_loss: 0.3741\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3698 - val_loss: 0.3773\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3674 - val_loss: 0.3817\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3773 - val_loss: 0.3787\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3601 - val_loss: 0.4198\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3647 - val_loss: 0.3636\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3564 - val_loss: 0.3699\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3582 - val_loss: 0.3875\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3689 - val_loss: 0.3667\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3507 - val_loss: 0.3927\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3490 - val_loss: 0.3632\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3473 - val_loss: 0.3623\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3462 - val_loss: 0.3595\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3461 - val_loss: 0.3809\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3447 - val_loss: 0.3637\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3580 - val_loss: 0.3739\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3443 - val_loss: 0.3562\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3428 - val_loss: 0.3726\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3417 - val_loss: 0.3569\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3645 - val_loss: 0.3649\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3402 - val_loss: 0.3648\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3577 - val_loss: 0.3559\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3592 - val_loss: 0.3708\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3492 - val_loss: 0.3568\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3408 - val_loss: 0.3724\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3591 - val_loss: 0.3630\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3472 - val_loss: 0.3701\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3387 - val_loss: 0.3670\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3363 - val_loss: 0.3535\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3354 - val_loss: 0.3504\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3340 - val_loss: 0.3660\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3336 - val_loss: 0.3505\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3316 - val_loss: 0.3749\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3320 - val_loss: 0.3494\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3317 - val_loss: 0.3522\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3315 - val_loss: 0.3534\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3335 - val_loss: 0.3693\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3300 - val_loss: 0.3663\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3290 - val_loss: 0.3538\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3287 - val_loss: 0.3505\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3304 - val_loss: 0.3594\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3294 - val_loss: 0.3496\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3274 - val_loss: 0.3488\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3268 - val_loss: 0.3624\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3255 - val_loss: 0.3532\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3264 - val_loss: 0.3469\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3285 - val_loss: 0.3540\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3286 - val_loss: 0.3506\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3258 - val_loss: 0.3569\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3267 - val_loss: 0.3518\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3248 - val_loss: 0.3531\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3237 - val_loss: 0.3606\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3240 - val_loss: 0.3444\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3230 - val_loss: 0.3527\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3234 - val_loss: 0.3475\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3227 - val_loss: 0.3594\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3222 - val_loss: 0.3514\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3223 - val_loss: 0.3531\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3236 - val_loss: 0.3551\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3392 - val_loss: 0.3466\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3218 - val_loss: 0.3462\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3226 - val_loss: 0.3451\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3225 - val_loss: 0.3452\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3217 - val_loss: 0.3594\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3229 - val_loss: 0.3454\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3200 - val_loss: 0.3545\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3203 - val_loss: 0.3422\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3184 - val_loss: 0.3484\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3186 - val_loss: 0.3518\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3198 - val_loss: 0.3457\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3180 - val_loss: 0.3495\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3180 - val_loss: 0.3422\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3175 - val_loss: 0.3425\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3165 - val_loss: 0.3418\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3156 - val_loss: 0.3415\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3156 - val_loss: 0.3441\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3166 - val_loss: 0.3465\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3153 - val_loss: 0.3457\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3158 - val_loss: 0.3491\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3142 - val_loss: 0.3407\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3151 - val_loss: 0.3478\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3137 - val_loss: 0.3509\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3141 - val_loss: 0.3393\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3136 - val_loss: 0.3401\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3117 - val_loss: 0.3380\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3115 - val_loss: 0.3512\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3110 - val_loss: 0.3435\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3110 - val_loss: 0.3377\n",
      "121/121 [==============================] - 0s 802us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9042 - val_loss: 3.4416\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5746 - val_loss: 1.4954\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4705 - val_loss: 0.4810\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4324 - val_loss: 0.4480\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4161 - val_loss: 0.4343\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4046 - val_loss: 0.4290\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3947 - val_loss: 0.4140\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3873 - val_loss: 0.4123\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3799 - val_loss: 0.4023\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3748 - val_loss: 0.3959\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3708 - val_loss: 0.3951\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3663 - val_loss: 0.3970\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3642 - val_loss: 0.3899\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3607 - val_loss: 0.3847\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3579 - val_loss: 0.3863\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3558 - val_loss: 0.3872\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3539 - val_loss: 0.3813\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3529 - val_loss: 0.3932\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3496 - val_loss: 0.3772\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3479 - val_loss: 0.3781\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3477 - val_loss: 0.3842\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3452 - val_loss: 0.3728\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3428 - val_loss: 0.3692\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3419 - val_loss: 0.3903\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3414 - val_loss: 0.3664\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3403 - val_loss: 0.3803\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3384 - val_loss: 0.3702\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3372 - val_loss: 0.3702\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3361 - val_loss: 0.3628\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3342 - val_loss: 0.3863\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3360 - val_loss: 0.3671\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3340 - val_loss: 0.3681\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3324 - val_loss: 0.3624\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3316 - val_loss: 0.3638\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3306 - val_loss: 0.3683\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3291 - val_loss: 0.3563\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3286 - val_loss: 0.3591\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3283 - val_loss: 0.3540\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3277 - val_loss: 0.3645\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3278 - val_loss: 0.3526\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3253 - val_loss: 0.3587\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3243 - val_loss: 0.3546\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3258 - val_loss: 0.3795\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3240 - val_loss: 0.3532\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3214 - val_loss: 0.3608\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3219 - val_loss: 0.3561\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3217 - val_loss: 0.3645\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3206 - val_loss: 0.3494\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3196 - val_loss: 0.3534\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3198 - val_loss: 0.3583\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3182 - val_loss: 0.3476\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3179 - val_loss: 0.3487\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3178 - val_loss: 0.3499\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3161 - val_loss: 0.3512\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3168 - val_loss: 0.3537\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3155 - val_loss: 0.3547\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3147 - val_loss: 0.3456\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3131 - val_loss: 0.3491\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3151 - val_loss: 0.3480\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3221 - val_loss: 0.3399\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3112 - val_loss: 0.3526\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3106 - val_loss: 0.3745\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3104 - val_loss: 0.3753\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3130 - val_loss: 0.4060\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3107 - val_loss: 0.4388\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3106 - val_loss: 0.4500\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3109 - val_loss: 0.5526\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3097 - val_loss: 0.5213\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3107 - val_loss: 0.6056\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3096 - val_loss: 0.6654\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3090 - val_loss: 0.7816\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3093 - val_loss: 1.0505\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3120 - val_loss: 2.3241\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3356 - val_loss: 3.5694\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3466 - val_loss: 0.6177\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3079 - val_loss: 0.3330\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3019 - val_loss: 0.3435\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3037 - val_loss: 0.3398\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3024 - val_loss: 0.3369\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3020 - val_loss: 0.3373\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3005 - val_loss: 0.3384\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3011 - val_loss: 0.3445\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2998 - val_loss: 0.3351\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2998 - val_loss: 0.3349\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2992 - val_loss: 0.3394\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2989 - val_loss: 0.3408\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2979 - val_loss: 0.3414\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2970 - val_loss: 0.3358\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2971 - val_loss: 0.3362\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2975 - val_loss: 0.3347\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2965 - val_loss: 0.3403\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2975 - val_loss: 0.3386\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2966 - val_loss: 0.3344\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2956 - val_loss: 0.3330\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2951 - val_loss: 0.3403\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2969 - val_loss: 0.3336\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2955 - val_loss: 0.3303\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2935 - val_loss: 0.3286\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2940 - val_loss: 0.3410\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2943 - val_loss: 0.3277\n",
      "121/121 [==============================] - 0s 804us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.7806 - val_loss: 1.3102\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3405 - val_loss: 1.3095\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3406 - val_loss: 1.3091\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3406 - val_loss: 1.3096\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3406 - val_loss: 1.3101\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3407 - val_loss: 1.3091\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3408 - val_loss: 1.3092\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3405 - val_loss: 1.3091\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3408 - val_loss: 1.3094\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3406 - val_loss: 1.3092\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3405 - val_loss: 1.3099\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3405 - val_loss: 1.3094\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3408 - val_loss: 1.3092\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3406 - val_loss: 1.3092\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3407 - val_loss: 1.3093\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3406 - val_loss: 1.3103\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3406 - val_loss: 1.3106\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3407 - val_loss: 1.3094\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3401 - val_loss: 1.3099\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3406 - val_loss: 1.3100\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3406 - val_loss: 1.3094\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3406 - val_loss: 1.3093\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3404 - val_loss: 1.3093\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3407 - val_loss: 1.3093\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3406 - val_loss: 1.3092\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3408 - val_loss: 1.3095\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3406 - val_loss: 1.3097\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3407 - val_loss: 1.3091\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3406 - val_loss: 1.3097\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3405 - val_loss: 1.3095\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3407 - val_loss: 1.3092\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3407 - val_loss: 1.3091\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3404 - val_loss: 1.3093\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3408 - val_loss: 1.3092\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3399 - val_loss: 1.3119\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3409 - val_loss: 1.3093\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3409 - val_loss: 1.3093\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3406 - val_loss: 1.3092\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3406 - val_loss: 1.3096\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3408 - val_loss: 1.3092\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3405 - val_loss: 1.3091\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3404 - val_loss: 1.3103\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3407 - val_loss: 1.3098\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3408 - val_loss: 1.3093\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3408 - val_loss: 1.3092\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3406 - val_loss: 1.3092\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3409 - val_loss: 1.3092\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3406 - val_loss: 1.3091\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3407 - val_loss: 1.3091\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3407 - val_loss: 1.3092\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3407 - val_loss: 1.3092\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3405 - val_loss: 1.3096\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3409 - val_loss: 1.3094\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3407 - val_loss: 1.3094\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3408 - val_loss: 1.3096\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3405 - val_loss: 1.3093\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3405 - val_loss: 1.3092\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3402 - val_loss: 1.3104\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3407 - val_loss: 1.3092\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3400 - val_loss: 1.3095\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3408 - val_loss: 1.3092\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3403 - val_loss: 1.3091\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3406 - val_loss: 1.3094\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3405 - val_loss: 1.3091\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3408 - val_loss: 1.3092\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3405 - val_loss: 1.3098\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3406 - val_loss: 1.3102\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3408 - val_loss: 1.3093\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3404 - val_loss: 1.3092\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3408 - val_loss: 1.3092\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3405 - val_loss: 1.3091\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3407 - val_loss: 1.3091\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3404 - val_loss: 1.3104\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3410 - val_loss: 1.3093\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3406 - val_loss: 1.3094\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3407 - val_loss: 1.3092\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3408 - val_loss: 1.3092\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3404 - val_loss: 1.3102\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3410 - val_loss: 1.3091\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3407 - val_loss: 1.3094\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3407 - val_loss: 1.3101\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3409 - val_loss: 1.3092\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3407 - val_loss: 1.3099\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3406 - val_loss: 1.3092\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3404 - val_loss: 1.3103\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3407 - val_loss: 1.3094\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3408 - val_loss: 1.3094\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3404 - val_loss: 1.3094\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3410 - val_loss: 1.3092\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3407 - val_loss: 1.3092\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3407 - val_loss: 1.3094\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3409 - val_loss: 1.3093\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3407 - val_loss: 1.3094\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3406 - val_loss: 1.3100\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3407 - val_loss: 1.3091\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3408 - val_loss: 1.3092\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3407 - val_loss: 1.3095\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3408 - val_loss: 1.3091\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3407 - val_loss: 1.3092\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3407 - val_loss: 1.3093\n",
      "121/121 [==============================] - 0s 853us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.8206 - val_loss: 1.3106\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3697 - val_loss: 1.3091\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3698 - val_loss: 1.3091\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3697 - val_loss: 1.3091\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3693 - val_loss: 1.3105\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3696 - val_loss: 1.3094\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3697 - val_loss: 1.3093\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3696 - val_loss: 1.3093\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3695 - val_loss: 1.3091\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3697 - val_loss: 1.3092\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3695 - val_loss: 1.3092\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3695 - val_loss: 1.3091\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3698 - val_loss: 1.3091\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3692 - val_loss: 1.3112\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3696 - val_loss: 1.3092\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3679 - val_loss: 1.3094\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3697 - val_loss: 1.3091\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3696 - val_loss: 1.3092\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3697 - val_loss: 1.3092\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3698 - val_loss: 1.3092\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3696 - val_loss: 1.3096\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3695 - val_loss: 1.3092\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3694 - val_loss: 1.3094\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3693 - val_loss: 1.3091\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3696 - val_loss: 1.3097\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3695 - val_loss: 1.3092\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3693 - val_loss: 1.3092\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3696 - val_loss: 1.3094\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3695 - val_loss: 1.3093\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3697 - val_loss: 1.3099\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3697 - val_loss: 1.3095\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3690 - val_loss: 1.3120\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3702 - val_loss: 1.3091\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3692 - val_loss: 1.3106\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3696 - val_loss: 1.3099\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3696 - val_loss: 1.3092\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3691 - val_loss: 1.3100\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3698 - val_loss: 1.3092\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3694 - val_loss: 1.3091\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3694 - val_loss: 1.3100\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3695 - val_loss: 1.3093\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3696 - val_loss: 1.3095\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3694 - val_loss: 1.3102\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3697 - val_loss: 1.3092\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3694 - val_loss: 1.3092\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3695 - val_loss: 1.3102\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3699 - val_loss: 1.3092\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3696 - val_loss: 1.3091\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3696 - val_loss: 1.3092\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3696 - val_loss: 1.3096\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3698 - val_loss: 1.3091\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3692 - val_loss: 1.3098\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3698 - val_loss: 1.3093\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3693 - val_loss: 1.3103\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3697 - val_loss: 1.3092\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3696 - val_loss: 1.3092\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3696 - val_loss: 1.3092\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3693 - val_loss: 1.3101\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3697 - val_loss: 1.3094\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3695 - val_loss: 1.3092\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3695 - val_loss: 1.3092\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3698 - val_loss: 1.3091\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3696 - val_loss: 1.3097\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3697 - val_loss: 1.3097\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3698 - val_loss: 1.3093\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3693 - val_loss: 1.3096\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3696 - val_loss: 1.3092\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3693 - val_loss: 1.3097\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3695 - val_loss: 1.3091\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3697 - val_loss: 1.3094\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3697 - val_loss: 1.3095\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3695 - val_loss: 1.3091\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3696 - val_loss: 1.3094\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3696 - val_loss: 1.3099\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3698 - val_loss: 1.3093\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3696 - val_loss: 1.3092\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3696 - val_loss: 1.3098\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3696 - val_loss: 1.3091\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3694 - val_loss: 1.3099\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3690 - val_loss: 1.3100\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3697 - val_loss: 1.3096\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3697 - val_loss: 1.3091\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3695 - val_loss: 1.3093\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3696 - val_loss: 1.3091\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3694 - val_loss: 1.3092\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3696 - val_loss: 1.3095\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3697 - val_loss: 1.3094\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3695 - val_loss: 1.3091\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3694 - val_loss: 1.3093\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3693 - val_loss: 1.3107\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3692 - val_loss: 1.3095\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3690 - val_loss: 1.3099\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3696 - val_loss: 1.3096\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3696 - val_loss: 1.3091\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3698 - val_loss: 1.3091\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3697 - val_loss: 1.3092\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3698 - val_loss: 1.3091\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3696 - val_loss: 1.3099\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3698 - val_loss: 1.3091\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3693 - val_loss: 1.3101\n",
      "121/121 [==============================] - 0s 868us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.7499 - val_loss: 1.3105\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3067 - val_loss: 1.3098\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.3078 - val_loss: 1.3091\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3072 - val_loss: 1.3096\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3077 - val_loss: 1.3091\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3075 - val_loss: 1.3093\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3078 - val_loss: 1.3091\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3076 - val_loss: 1.3095\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3069 - val_loss: 1.3091\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3076 - val_loss: 1.3093\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3077 - val_loss: 1.3091\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3073 - val_loss: 1.3093\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3075 - val_loss: 1.3096\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3076 - val_loss: 1.3098\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3074 - val_loss: 1.3100\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3075 - val_loss: 1.3093\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3074 - val_loss: 1.3097\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3078 - val_loss: 1.3092\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3077 - val_loss: 1.3092\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3076 - val_loss: 1.3097\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3076 - val_loss: 1.3093\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3073 - val_loss: 1.3099\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3074 - val_loss: 1.3093\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3077 - val_loss: 1.3092\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3071 - val_loss: 1.3105\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3079 - val_loss: 1.3093\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3077 - val_loss: 1.3091\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3076 - val_loss: 1.3094\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3077 - val_loss: 1.3091\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3075 - val_loss: 1.3094\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3074 - val_loss: 1.3098\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3077 - val_loss: 1.3091\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3077 - val_loss: 1.3095\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3077 - val_loss: 1.3091\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3077 - val_loss: 1.3091\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3077 - val_loss: 1.3092\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3074 - val_loss: 1.3096\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3074 - val_loss: 1.3094\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3078 - val_loss: 1.3092\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3076 - val_loss: 1.3093\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3077 - val_loss: 1.3092\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3077 - val_loss: 1.3092\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3077 - val_loss: 1.3091\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3077 - val_loss: 1.3092\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3072 - val_loss: 1.3094\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3076 - val_loss: 1.3093\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3075 - val_loss: 1.3094\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3075 - val_loss: 1.3096\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3074 - val_loss: 1.3097\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3077 - val_loss: 1.3092\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3072 - val_loss: 1.3095\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3077 - val_loss: 1.3091\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3075 - val_loss: 1.3093\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3076 - val_loss: 1.3101\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3077 - val_loss: 1.3092\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3074 - val_loss: 1.3096\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3078 - val_loss: 1.3092\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3077 - val_loss: 1.3092\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3077 - val_loss: 1.3091\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3077 - val_loss: 1.3092\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3077 - val_loss: 1.3092\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3074 - val_loss: 1.3091\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3074 - val_loss: 1.3096\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3076 - val_loss: 1.3092\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3078 - val_loss: 1.3092\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3076 - val_loss: 1.3096\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3073 - val_loss: 1.3093\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3075 - val_loss: 1.3092\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3074 - val_loss: 1.3097\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3076 - val_loss: 1.3091\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3075 - val_loss: 1.3101\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3075 - val_loss: 1.3093\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3076 - val_loss: 1.3091\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3073 - val_loss: 1.3102\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3076 - val_loss: 1.3093\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3077 - val_loss: 1.3093\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3077 - val_loss: 1.3092\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3075 - val_loss: 1.3097\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3073 - val_loss: 1.3095\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3072 - val_loss: 1.3099\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3078 - val_loss: 1.3091\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3077 - val_loss: 1.3094\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3076 - val_loss: 1.3092\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3078 - val_loss: 1.3091\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3077 - val_loss: 1.3092\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3077 - val_loss: 1.3093\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3077 - val_loss: 1.3093\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3075 - val_loss: 1.3093\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3074 - val_loss: 1.3091\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3074 - val_loss: 1.3095\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3072 - val_loss: 1.3096\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3077 - val_loss: 1.3092\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3076 - val_loss: 1.3093\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3077 - val_loss: 1.3095\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3075 - val_loss: 1.3099\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3079 - val_loss: 1.3092\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3076 - val_loss: 1.3094\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3077 - val_loss: 1.3091\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3078 - val_loss: 1.3092\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3076 - val_loss: 1.3094\n",
      "121/121 [==============================] - 0s 729us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8923 - val_loss: 1.9428\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5429 - val_loss: 2.5244\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4703 - val_loss: 0.4844\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4566 - val_loss: 0.5610\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4272 - val_loss: 0.4318\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3972 - val_loss: 0.4483\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3867 - val_loss: 0.3854\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3748 - val_loss: 0.4231\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3726 - val_loss: 0.3803\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3665 - val_loss: 0.4045\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3589 - val_loss: 0.3841\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3564 - val_loss: 0.3990\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3518 - val_loss: 0.3822\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3490 - val_loss: 0.3914\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3488 - val_loss: 0.3915\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3446 - val_loss: 0.3706\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3404 - val_loss: 0.3579\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3391 - val_loss: 0.4175\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3363 - val_loss: 0.3513\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3340 - val_loss: 0.4229\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3397 - val_loss: 0.3434\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3324 - val_loss: 0.4037\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3271 - val_loss: 0.3421\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3258 - val_loss: 0.3512\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3248 - val_loss: 0.3547\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3607 - val_loss: 0.3554\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3648 - val_loss: 0.3666\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3332 - val_loss: 0.3545\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3226 - val_loss: 0.3501\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3166 - val_loss: 0.3485\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3138 - val_loss: 0.3579\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3125 - val_loss: 0.3373\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3103 - val_loss: 0.3348\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3105 - val_loss: 0.3720\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3072 - val_loss: 0.3426\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3057 - val_loss: 0.3472\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3027 - val_loss: 0.3436\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3031 - val_loss: 0.3396\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3025 - val_loss: 0.3636\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2986 - val_loss: 0.3382\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3007 - val_loss: 0.3481\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2956 - val_loss: 0.3673\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2984 - val_loss: 0.3209\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2941 - val_loss: 0.3415\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2931 - val_loss: 0.3189\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2944 - val_loss: 0.4839\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3036 - val_loss: 0.3697\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2978 - val_loss: 1.9167\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3211 - val_loss: 0.7359\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2937 - val_loss: 0.3222\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2927 - val_loss: 0.3645\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2895 - val_loss: 0.3137\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2909 - val_loss: 0.3283\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2861 - val_loss: 0.3176\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2856 - val_loss: 0.3439\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2839 - val_loss: 0.3178\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2839 - val_loss: 0.3338\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2838 - val_loss: 0.3091\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2814 - val_loss: 0.3560\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2806 - val_loss: 0.3203\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2815 - val_loss: 0.4033\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2798 - val_loss: 0.3061\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2792 - val_loss: 0.3381\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2785 - val_loss: 0.3237\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2772 - val_loss: 0.3172\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2773 - val_loss: 0.3343\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2759 - val_loss: 0.3165\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2756 - val_loss: 0.3215\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2749 - val_loss: 0.3030\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2764 - val_loss: 0.3379\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2747 - val_loss: 0.3231\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2724 - val_loss: 0.3295\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2715 - val_loss: 0.3162\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2738 - val_loss: 0.3207\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2718 - val_loss: 0.3085\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2711 - val_loss: 0.4138\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2719 - val_loss: 0.3584\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2701 - val_loss: 0.3042\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2709 - val_loss: 0.3419\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2702 - val_loss: 0.3163\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2688 - val_loss: 0.3177\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2684 - val_loss: 0.3217\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2670 - val_loss: 0.3062\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2682 - val_loss: 0.3242\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2670 - val_loss: 0.2988\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2678 - val_loss: 0.4489\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2675 - val_loss: 0.4292\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2738 - val_loss: 0.3155\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2678 - val_loss: 0.4267\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2674 - val_loss: 0.3017\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2633 - val_loss: 0.4148\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2715 - val_loss: 0.3324\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2676 - val_loss: 0.3529\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2653 - val_loss: 0.3034\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2659 - val_loss: 0.3320\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2658 - val_loss: 0.3010\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2613 - val_loss: 0.3223\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2619 - val_loss: 0.3078\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2619 - val_loss: 0.3095\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2617 - val_loss: 0.3188\n",
      "121/121 [==============================] - 0s 808us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8916 - val_loss: 4.8279\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8370 - val_loss: 0.9379\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5062 - val_loss: 1.5099\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5171 - val_loss: 0.4700\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3994 - val_loss: 0.4060\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3851 - val_loss: 0.3881\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3741 - val_loss: 0.3987\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3706 - val_loss: 0.3849\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3639 - val_loss: 0.3894\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3567 - val_loss: 0.3845\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3539 - val_loss: 0.3710\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3492 - val_loss: 0.3626\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3459 - val_loss: 0.3674\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3430 - val_loss: 0.3584\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3426 - val_loss: 0.3679\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3388 - val_loss: 0.3682\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3391 - val_loss: 0.3595\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3349 - val_loss: 0.3575\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3385 - val_loss: 0.3597\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3316 - val_loss: 0.3529\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3286 - val_loss: 0.3514\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3270 - val_loss: 0.3539\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3289 - val_loss: 0.3484\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3275 - val_loss: 0.3563\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3228 - val_loss: 0.3482\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3211 - val_loss: 0.3580\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3203 - val_loss: 0.3367\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3162 - val_loss: 0.3524\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3155 - val_loss: 0.3434\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3143 - val_loss: 0.3390\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3124 - val_loss: 0.3585\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3121 - val_loss: 0.3470\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3092 - val_loss: 0.3315\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3080 - val_loss: 0.3492\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3078 - val_loss: 0.3343\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3055 - val_loss: 0.3395\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3033 - val_loss: 0.3303\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3066 - val_loss: 0.3472\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3011 - val_loss: 0.3292\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3006 - val_loss: 0.3954\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3011 - val_loss: 0.3259\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3033 - val_loss: 0.3970\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2991 - val_loss: 0.3194\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2972 - val_loss: 0.3798\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2975 - val_loss: 0.3168\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2928 - val_loss: 0.3588\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2920 - val_loss: 0.3182\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2925 - val_loss: 0.3353\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2906 - val_loss: 0.3151\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2899 - val_loss: 0.3218\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2879 - val_loss: 0.3344\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2881 - val_loss: 0.3572\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2919 - val_loss: 0.3138\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2892 - val_loss: 0.3768\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2877 - val_loss: 0.3467\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2885 - val_loss: 0.3982\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2870 - val_loss: 0.3114\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2835 - val_loss: 0.3387\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2839 - val_loss: 0.3272\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2829 - val_loss: 0.3220\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2808 - val_loss: 0.3028\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2790 - val_loss: 0.3266\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2858 - val_loss: 0.3149\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2774 - val_loss: 0.3143\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2787 - val_loss: 0.3304\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2761 - val_loss: 0.3216\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2774 - val_loss: 0.3464\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2757 - val_loss: 0.3019\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2756 - val_loss: 0.3220\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2746 - val_loss: 0.3109\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2729 - val_loss: 0.3063\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2737 - val_loss: 0.3348\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2743 - val_loss: 0.2966\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2727 - val_loss: 0.3267\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2718 - val_loss: 0.3083\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2728 - val_loss: 0.3228\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2732 - val_loss: 0.3114\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2717 - val_loss: 0.3188\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2700 - val_loss: 0.3354\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2700 - val_loss: 0.3012\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2698 - val_loss: 0.3472\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2688 - val_loss: 0.2997\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2683 - val_loss: 0.3239\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2754 - val_loss: 0.2998\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2671 - val_loss: 0.4095\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2782 - val_loss: 0.3158\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2697 - val_loss: 0.3542\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2669 - val_loss: 0.3006\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2656 - val_loss: 0.3083\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2682 - val_loss: 0.3043\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2662 - val_loss: 0.3203\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2671 - val_loss: 0.2976\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2653 - val_loss: 0.3216\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2628 - val_loss: 0.3082\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2631 - val_loss: 0.3133\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2640 - val_loss: 0.3017\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2619 - val_loss: 0.3083\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2607 - val_loss: 0.3188\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2618 - val_loss: 0.3080\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2606 - val_loss: 0.3062\n",
      "121/121 [==============================] - 0s 852us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8490 - val_loss: 0.5541\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4813 - val_loss: 0.8923\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4288 - val_loss: 0.5113\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4041 - val_loss: 0.4147\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3825 - val_loss: 0.5169\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3759 - val_loss: 0.7948\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3664 - val_loss: 0.5838\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3581 - val_loss: 0.5863\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3518 - val_loss: 0.3952\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3464 - val_loss: 0.4402\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3404 - val_loss: 0.3682\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3367 - val_loss: 0.3702\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3333 - val_loss: 0.3660\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3284 - val_loss: 0.3811\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3272 - val_loss: 0.3704\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3228 - val_loss: 0.3583\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3205 - val_loss: 0.3636\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3175 - val_loss: 0.3575\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3142 - val_loss: 0.3497\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3117 - val_loss: 0.3437\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3105 - val_loss: 0.3716\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3080 - val_loss: 0.3368\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3054 - val_loss: 0.3595\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3041 - val_loss: 0.3394\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3031 - val_loss: 0.4126\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3021 - val_loss: 0.3918\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3015 - val_loss: 0.4709\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2990 - val_loss: 0.4446\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3022 - val_loss: 0.8542\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3003 - val_loss: 0.8951\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3050 - val_loss: 1.0928\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3104 - val_loss: 1.5590\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3192 - val_loss: 1.3149\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3022 - val_loss: 0.3994\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2903 - val_loss: 0.3768\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2896 - val_loss: 0.3511\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2879 - val_loss: 0.3500\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2873 - val_loss: 0.3500\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2857 - val_loss: 0.3427\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2858 - val_loss: 0.3456\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2837 - val_loss: 0.3674\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2838 - val_loss: 0.3314\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2809 - val_loss: 0.3385\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2844 - val_loss: 0.3280\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2821 - val_loss: 0.3416\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2800 - val_loss: 0.3377\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2780 - val_loss: 0.3397\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2782 - val_loss: 0.3251\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2794 - val_loss: 0.3528\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2763 - val_loss: 0.3259\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2770 - val_loss: 0.3402\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2738 - val_loss: 0.3331\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2752 - val_loss: 0.3396\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2739 - val_loss: 0.3181\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2735 - val_loss: 0.3578\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2719 - val_loss: 0.3223\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2703 - val_loss: 0.3274\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2705 - val_loss: 0.3396\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2705 - val_loss: 0.3247\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2674 - val_loss: 0.3257\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2693 - val_loss: 0.3176\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2671 - val_loss: 0.3151\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2670 - val_loss: 0.3194\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2642 - val_loss: 0.3217\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2664 - val_loss: 0.3143\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2674 - val_loss: 0.3116\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2662 - val_loss: 0.3299\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2632 - val_loss: 0.3118\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2637 - val_loss: 0.3453\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2621 - val_loss: 0.3076\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2614 - val_loss: 0.3288\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2619 - val_loss: 0.3058\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2628 - val_loss: 0.3227\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2615 - val_loss: 0.3009\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2593 - val_loss: 0.3876\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2594 - val_loss: 0.3080\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2599 - val_loss: 0.3694\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2586 - val_loss: 0.3032\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2579 - val_loss: 0.3709\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2565 - val_loss: 0.3384\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2586 - val_loss: 0.5504\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2591 - val_loss: 0.4245\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2573 - val_loss: 0.4885\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2554 - val_loss: 0.3893\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2560 - val_loss: 0.5895\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2578 - val_loss: 0.5854\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2589 - val_loss: 0.7348\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2587 - val_loss: 0.5458\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2568 - val_loss: 0.6280\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2552 - val_loss: 0.4310\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2530 - val_loss: 0.5963\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2542 - val_loss: 0.4504\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2549 - val_loss: 0.6894\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2541 - val_loss: 0.4416\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2516 - val_loss: 0.3627\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2501 - val_loss: 0.3009\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2489 - val_loss: 0.3096\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2486 - val_loss: 0.2971\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2494 - val_loss: 0.3216\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2475 - val_loss: 0.3010\n",
      "121/121 [==============================] - 0s 844us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tmoia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [            nan  7.59299033e-01             nan             nan\n",
      "  7.68977417e-01  6.15338655e-01             nan  7.57320307e-01\n",
      " -4.98768726e-04  7.82552010e-01]\n",
      "  warnings.warn(\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7527 - val_loss: 1.8207\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7655 - val_loss: 1.0785\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5549 - val_loss: 0.8005\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3885 - val_loss: 0.4142\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3718 - val_loss: 0.3989\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3586 - val_loss: 0.3954\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3523 - val_loss: 0.3816\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3482 - val_loss: 0.3753\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3389 - val_loss: 0.3744\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3373 - val_loss: 0.3648\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3314 - val_loss: 0.3699\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3280 - val_loss: 0.3627\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3214 - val_loss: 0.3676\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3213 - val_loss: 0.3498\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3163 - val_loss: 0.3535\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3122 - val_loss: 0.3452\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3122 - val_loss: 0.3482\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3073 - val_loss: 0.3406\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3052 - val_loss: 0.3434\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3054 - val_loss: 0.3691\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3014 - val_loss: 0.3227\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3007 - val_loss: 0.3785\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2982 - val_loss: 0.3672\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2959 - val_loss: 0.3540\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2963 - val_loss: 0.3338\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2917 - val_loss: 0.3346\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2889 - val_loss: 0.3272\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2900 - val_loss: 0.3209\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2875 - val_loss: 0.3524\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2858 - val_loss: 0.3131\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2859 - val_loss: 0.3189\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2845 - val_loss: 0.3141\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2816 - val_loss: 0.3376\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2810 - val_loss: 0.3711\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2880 - val_loss: 0.3127\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2839 - val_loss: 0.3245\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2809 - val_loss: 0.3579\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2811 - val_loss: 0.3085\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2782 - val_loss: 0.3900\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2804 - val_loss: 0.3123\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2755 - val_loss: 0.3308\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2749 - val_loss: 0.3468\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2843 - val_loss: 0.3036\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2741 - val_loss: 0.3313\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2722 - val_loss: 0.3091\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2716 - val_loss: 0.3302\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2721 - val_loss: 0.2955\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2704 - val_loss: 0.3147\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2705 - val_loss: 0.3272\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2692 - val_loss: 0.3331\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2696 - val_loss: 0.2989\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2685 - val_loss: 0.4000\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2691 - val_loss: 0.3405\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2707 - val_loss: 0.3108\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2677 - val_loss: 0.3633\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2671 - val_loss: 0.2969\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2667 - val_loss: 0.3006\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2652 - val_loss: 0.2920\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2646 - val_loss: 0.3336\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2634 - val_loss: 0.3873\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2694 - val_loss: 0.2903\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2659 - val_loss: 0.3467\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2640 - val_loss: 0.3175\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2641 - val_loss: 1.0655\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2695 - val_loss: 0.4109\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2643 - val_loss: 0.2982\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2617 - val_loss: 0.3004\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2637 - val_loss: 0.3130\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2636 - val_loss: 0.3444\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2601 - val_loss: 0.3012\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2599 - val_loss: 0.3102\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2610 - val_loss: 0.3169\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2607 - val_loss: 0.3072\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2599 - val_loss: 0.3042\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2578 - val_loss: 0.3112\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2588 - val_loss: 0.3106\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2589 - val_loss: 0.3173\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2595 - val_loss: 0.2942\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2586 - val_loss: 0.2962\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2567 - val_loss: 0.2974\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2576 - val_loss: 0.3076\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2567 - val_loss: 0.3084\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2570 - val_loss: 0.3153\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2563 - val_loss: 0.3059\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2562 - val_loss: 0.2987\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2554 - val_loss: 0.3086\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2545 - val_loss: 0.3051\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2535 - val_loss: 0.3258\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2551 - val_loss: 0.3013\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2537 - val_loss: 0.3036\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2542 - val_loss: 0.3039\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2538 - val_loss: 0.3044\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2543 - val_loss: 0.3000\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2544 - val_loss: 0.3106\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2534 - val_loss: 0.3021\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2535 - val_loss: 0.3150\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2541 - val_loss: 0.2986\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2528 - val_loss: 0.2951\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2532 - val_loss: 0.3188\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2517 - val_loss: 0.3076\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=KerasRegressor(loss=&#x27;mse&#x27;, model=&lt;function build_model at 0x000002074797F9C0&gt;, n_hidden=1, n_neurons=30, optimizer=&lt;class &#x27;keras.src.optimizers.sgd.SGD&#x27;&gt;, optimizer__lr=0.003),\n",
       "                   param_distributions={&#x27;n_hidden&#x27;: [0, 1, 2, 3],\n",
       "                                        &#x27;n_neurons&#x27;: array([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91]),\n",
       "                                        &#x27;optimizer__lr&#x27;: array([0.0003 , 0.00327, 0.00624, 0.00921, 0.01218, 0.01515, 0.01812,\n",
       "       0.02109, 0.02406, 0.02703])})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=KerasRegressor(loss=&#x27;mse&#x27;, model=&lt;function build_model at 0x000002074797F9C0&gt;, n_hidden=1, n_neurons=30, optimizer=&lt;class &#x27;keras.src.optimizers.sgd.SGD&#x27;&gt;, optimizer__lr=0.003),\n",
       "                   param_distributions={&#x27;n_hidden&#x27;: [0, 1, 2, 3],\n",
       "                                        &#x27;n_neurons&#x27;: array([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91]),\n",
       "                                        &#x27;optimizer__lr&#x27;: array([0.0003 , 0.00327, 0.00624, 0.00921, 0.01218, 0.01515, 0.01812,\n",
       "       0.02109, 0.02406, 0.02703])})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>KerasRegressor(\n",
       "\tmodel=&lt;function build_model at 0x000002074797F9C0&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=&lt;class &#x27;keras.src.optimizers.sgd.SGD&#x27;&gt;\n",
       "\tloss=mse\n",
       "\tmetrics=None\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=1\n",
       "\tn_neurons=30\n",
       "\tn_hidden=1\n",
       "\toptimizer__lr=0.003\n",
       ")</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>KerasRegressor(\n",
       "\tmodel=&lt;function build_model at 0x000002074797F9C0&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=&lt;class &#x27;keras.src.optimizers.sgd.SGD&#x27;&gt;\n",
       "\tloss=mse\n",
       "\tmetrics=None\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=1\n",
       "\tn_neurons=30\n",
       "\tn_hidden=1\n",
       "\toptimizer__lr=0.003\n",
       ")</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=KerasRegressor(loss='mse', model=<function build_model at 0x000002074797F9C0>, n_hidden=1, n_neurons=30, optimizer=<class 'keras.src.optimizers.sgd.SGD'>, optimizer__lr=0.003),\n",
       "                   param_distributions={'n_hidden': [0, 1, 2, 3],\n",
       "                                        'n_neurons': array([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91]),\n",
       "                                        'optimizer__lr': array([0.0003 , 0.00327, 0.00624, 0.00921, 0.01218, 0.01515, 0.01812,\n",
       "       0.02109, 0.02406, 0.02703])})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)\n",
    "rnd_search_cv.fit(X_train_scaled, y_train, epochs=100,\n",
    "                  validation_data=(X_valid_scaled, y_valid),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer__lr': 0.00921, 'n_neurons': 51, 'n_hidden': 2}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7825520103113783"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rnd_search_cv.best_estimator_.model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
